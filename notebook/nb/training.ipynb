{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLULE 1 : PR√âPARATION DONN√âES CONVERSATIONNELLES GYM-EXERCISE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ CELLULE 1 : Donn√©es conversationnelles GYM-Exercise\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# === INSTALLATION AUTO ===\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"üì• Installation de {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ {package} install√©\")\n",
    "\n",
    "required_packages = [\"datasets\", \"accelerate\", \"evaluate\"]\n",
    "for pkg in required_packages:\n",
    "    install_if_missing(pkg)\n",
    "\n",
    "# === IMPORTS ===\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    MT5ForConditionalGeneration, \n",
    "    MT5Tokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîß Device utilis√©: {device}\")\n",
    "\n",
    "# === CHARGEMENT DATASET CONVERSATIONNEL ===\n",
    "print(f\"\\nüì• Chargement du dataset GYM-Exercise conversationnel...\")\n",
    "gym_df = pd.read_parquet(\"hf://datasets/onurSakar/GYM-Exercise/data/train-00000-of-00001.parquet\")\n",
    "print(f\"‚úÖ Dataset charg√©: {len(gym_df)} conversations\")\n",
    "\n",
    "# === PARSING DU FORMAT CONVERSATIONNEL ===\n",
    "print(f\"\\nüîÑ Parsing du format conversationnel...\")\n",
    "\n",
    "def parse_conversational_format(df):\n",
    "    \"\"\"Parse le format [INST]...[/INST] en questions-r√©ponses\"\"\"\n",
    "    parsed_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = str(row['text'])\n",
    "        \n",
    "        # Pattern pour extraire question et r√©ponse\n",
    "        # Format: <s>[INST] <<SYS>>...<<</SYS>> QUESTION [/INST]R√âPONSE</s>\n",
    "        \n",
    "        # Extraction de la question\n",
    "        question_match = re.search(r'<<</SYS>>\\s*(.*?)\\s*\\[/INST\\]', text, re.DOTALL)\n",
    "        if not question_match:\n",
    "            continue\n",
    "        \n",
    "        question = question_match.group(1).strip()\n",
    "        \n",
    "        # Extraction de la r√©ponse\n",
    "        response_match = re.search(r'\\[/INST\\]\\s*(.*?)(?:</s>|$)', text, re.DOTALL)\n",
    "        if not response_match:\n",
    "            continue\n",
    "        \n",
    "        response = response_match.group(1).strip()\n",
    "        \n",
    "        # Filtrage des questions/r√©ponses de qualit√©\n",
    "        if (len(question) > 10 and len(response) > 20 and \n",
    "            len(question) < 200 and len(response) < 1000):\n",
    "            \n",
    "            parsed_data.append({\n",
    "                \"input\": question,\n",
    "                \"output\": response\n",
    "            })\n",
    "    \n",
    "    return parsed_data\n",
    "\n",
    "# Parse du dataset\n",
    "gym_parsed_data = parse_conversational_format(gym_df)\n",
    "print(f\"‚úÖ {len(gym_parsed_data)} conversations pars√©es avec succ√®s\")\n",
    "\n",
    "# √âchantillon du parsing\n",
    "print(f\"\\nüéØ Exemples de conversations pars√©es :\")\n",
    "for i in range(min(3, len(gym_parsed_data))):\n",
    "    example = gym_parsed_data[i]\n",
    "    print(f\"\\n--- Exemple {i+1} ---\")\n",
    "    print(f\"‚ùì Question: {example['input'][:80]}...\")\n",
    "    print(f\"ü§ñ R√©ponse: {example['output'][:100]}...\")\n",
    "\n",
    "# === AM√âLIORATION DES R√âPONSES POUR LE COACHING ===\n",
    "print(f\"\\nüèãÔ∏è Transformation en style coaching professionnel...\")\n",
    "\n",
    "def enhance_gym_responses(parsed_data, max_examples=800):\n",
    "    \"\"\"Am√©liore les r√©ponses avec un style coaching professionnel\"\"\"\n",
    "    enhanced_data = []\n",
    "    \n",
    "    for example in parsed_data[:max_examples]:\n",
    "        question = example['input']\n",
    "        original_response = example['output']\n",
    "        \n",
    "        # D√©tection du type de question\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # Style coaching adapt√© selon le type\n",
    "        if any(kw in question_lower for kw in ['build muscle', 'gain muscle', 'muscle building']):\n",
    "            enhanced_response = f\"\"\"üí™ **PRISE DE MUSCLE - R√©ponse Coach :**\n",
    "\n",
    "{original_response}\n",
    "\n",
    "‚úÖ **Conseils additionnels :**\n",
    "‚Ä¢ Progression graduelle : +2.5kg/semaine\n",
    "‚Ä¢ Repos 48-72h entre s√©ances m√™me muscle\n",
    "‚Ä¢ Nutrition : 1.8-2.2g prot√©ines/kg de poids\"\"\"\n",
    "        \n",
    "        elif any(kw in question_lower for kw in ['lose weight', 'weight loss', 'fat loss']):\n",
    "            enhanced_response = f\"\"\"üî• **PERTE DE POIDS - R√©ponse Coach :**\n",
    "\n",
    "{original_response}\n",
    "\n",
    "‚úÖ **Strat√©gie compl√®te :**\n",
    "‚Ä¢ D√©ficit calorique mod√©r√© (-300-500 cal/jour)\n",
    "‚Ä¢ Combinaison cardio + musculation\n",
    "‚Ä¢ Patience : 0.5-1kg/semaine = durable\"\"\"\n",
    "        \n",
    "        elif any(kw in question_lower for kw in ['exercise', 'workout', 'training']):\n",
    "            enhanced_response = f\"\"\"üèãÔ∏è **ENTRA√éNEMENT - R√©ponse Coach :**\n",
    "\n",
    "{original_response}\n",
    "\n",
    "‚úÖ **Points cl√©s s√©curit√© :**\n",
    "‚Ä¢ √âchauffement 5-10min obligatoire\n",
    "‚Ä¢ Technique avant charge\n",
    "‚Ä¢ √âcouter son corps = priorit√©\"\"\"\n",
    "        \n",
    "        elif any(kw in question_lower for kw in ['nutrition', 'diet', 'eating']):\n",
    "            enhanced_response = f\"\"\"üçé **NUTRITION - R√©ponse Coach :**\n",
    "\n",
    "{original_response}\n",
    "\n",
    "‚úÖ **R√®gles d'or :**\n",
    "‚Ä¢ R√©gularit√© > perfection\n",
    "‚Ä¢ Hydratation : 35ml/kg de poids\n",
    "‚Ä¢ L√©gumes √† chaque repas\"\"\"\n",
    "        \n",
    "        else:\n",
    "            # Format g√©n√©ral coaching\n",
    "            enhanced_response = f\"\"\"üí° **CONSEIL COACH :**\n",
    "\n",
    "{original_response}\n",
    "\n",
    "‚úÖ **Rappel important :** Consistance et patience sont vos meilleurs alli√©s !\"\"\"\n",
    "        \n",
    "        enhanced_data.append({\n",
    "            \"input\": question,\n",
    "            \"output\": enhanced_response\n",
    "        })\n",
    "    \n",
    "    return enhanced_data\n",
    "\n",
    "# Am√©lioration des r√©ponses\n",
    "gym_enhanced_data = enhance_gym_responses(gym_parsed_data)\n",
    "print(f\"‚úÖ {len(gym_enhanced_data)} r√©ponses am√©lior√©es en style coaching\")\n",
    "\n",
    "# === EXPERTISE COACHING ADDITIONNELLE ===\n",
    "print(f\"\\nüß† Ajout d'expertise coaching sp√©cialis√©e...\")\n",
    "\n",
    "expert_coaching_data = [\n",
    "    {\n",
    "        \"input\": \"Je d√©bute compl√®tement en sport, par o√π commencer ?\",\n",
    "        \"output\": \"\"\"üöÄ **PLAN DE D√âMARRAGE D√âBUTANT COMPLET :**\n",
    "\n",
    "**üìÖ SEMAINES 1-2 : Cr√©ation de l'habitude**\n",
    "‚Ä¢ 3 s√©ances de 20 minutes (lundi, mercredi, vendredi)\n",
    "‚Ä¢ Marche rapide 15min + √©tirements 5min\n",
    "‚Ä¢ Objectif : R√âGULARIT√â, pas performance\n",
    "\n",
    "**üìÖ SEMAINES 3-4 : Introduction exercices**\n",
    "‚Ä¢ Ajoutez 5 exercices au poids du corps\n",
    "‚Ä¢ Squats, pompes (genoux), planche, fentes, jumping jacks\n",
    "‚Ä¢ 2 s√©ries de 8-12 r√©p√©titions chacun\n",
    "\n",
    "**üéØ CL√âS DU SUCC√àS :**\n",
    "‚úÖ Commencez PETIT mais soyez CONSTANT\n",
    "‚úÖ Hydratation : 2L d'eau minimum/jour\n",
    "‚úÖ Sommeil : 7-8h pour r√©cup√©ration\n",
    "‚úÖ C√©l√©brez chaque petite victoire !\n",
    "\n",
    "üí™ **MOTIVATION :** Vous venez de prendre la MEILLEURE d√©cision de votre vie !\"\"\"\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"Programme sp√©cial femme d√©butante perte de poids\",\n",
    "        \"output\": \"\"\"üë©‚Äçüí™ **PROGRAMME FEMME PERTE DE POIDS OPTIMIS√â :**\n",
    "\n",
    "**üî• CARDIO ADAPT√â (3x/semaine) :**\n",
    "‚Ä¢ Lundi : Marche rapide 30min + escaliers 10min\n",
    "‚Ä¢ Mercredi : Danse/Zumba 45min (fun + efficace)\n",
    "‚Ä¢ Vendredi : V√©lo/elliptique 35min intensit√© mod√©r√©e\n",
    "\n",
    "**üí™ RENFORCEMENT CIBL√â (2x/semaine) :**\n",
    "‚Ä¢ Mardi : Haut du corps + core (focus tonification)\n",
    "‚Ä¢ Jeudi : Bas du corps + fessiers (sculpter)\n",
    "\n",
    "**üçé NUTRITION SIMPLE ET EFFICACE :**\n",
    "‚Ä¢ Petit-d√©j : Prot√©ines + fruits + c√©r√©ales compl√®tes\n",
    "‚Ä¢ D√©jeuner : L√©gumes + prot√©ines maigres + f√©culents\n",
    "‚Ä¢ D√Æner : L√©ger, privil√©gier l√©gumes + prot√©ines\n",
    "‚Ä¢ Collations : Fruits, yaourt grec, amandes\n",
    "\n",
    "**üìà OBJECTIFS R√âALISTES :**\n",
    "‚Ä¢ Perte : 0.5-1kg/semaine maximum\n",
    "‚Ä¢ Mesures : Tour de taille, cuisses (+ important que balance)\n",
    "‚Ä¢ Photos : 1x/semaine m√™me tenue, m√™me pose\n",
    "\n",
    "üåü **VOUS √äTES CAPABLE DE R√âUSSIR !**\"\"\"\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"Je stagne depuis 2 mois, comment relancer ?\",\n",
    "        \"output\": \"\"\"üîÑ **STRAT√âGIE ANTI-PLATEAU COMPL√àTE :**\n",
    "\n",
    "**üéØ POURQUOI √áA STAGNE :**\n",
    "‚Ä¢ Votre corps s'adapte = SIGNE DE PROGR√àS !\n",
    "‚Ä¢ Routine trop r√©p√©titive\n",
    "‚Ä¢ Possible sous-alimentation ou surentra√Ænement\n",
    "\n",
    "**üí• SOLUTIONS IMM√âDIATES :**\n",
    "\n",
    "**1. SHOCK TRAINING (1 semaine) :**\n",
    "‚Ä¢ Changez COMPL√àTEMENT votre routine\n",
    "‚Ä¢ Nouveaux exercices, nouvelles amplitudes\n",
    "‚Ä¢ Intensit√© diff√©rente (force ‚Üí endurance)\n",
    "\n",
    "**2. SEMAINE DE D√âCHARGE :**\n",
    "‚Ä¢ R√©duisez volume de 50%\n",
    "‚Ä¢ Gardez intensit√© mais moins de s√©ries\n",
    "‚Ä¢ Plus de mobilit√©/√©tirements\n",
    "\n",
    "**3. NUTRITION RESET :**\n",
    "‚Ä¢ Calculez vos calories r√©elles\n",
    "‚Ä¢ +200 cal si sous-alimentation\n",
    "‚Ä¢ V√©rifiez prot√©ines : 1.8-2g/kg\n",
    "\n",
    "**4. PROGRESSION FORC√âE :**\n",
    "‚Ä¢ Techniques avanc√©es : drop sets, rest-pause\n",
    "‚Ä¢ +2.5kg ou +2 reps OBLIGATOIRE chaque semaine\n",
    "\n",
    "üí° **PATIENCE + PERSISTENCE = VICTOIRE GARANTIE !**\"\"\"\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"Mal au dos apr√®s squats, que faire ?\",\n",
    "        \"output\": \"\"\"‚ö†Ô∏è **PROTOCOLE URGENCE MAL DE DOS :**\n",
    "\n",
    "**üö® IMM√âDIATEMENT :**\n",
    "‚Ä¢ ARR√äT complet des squats\n",
    "‚Ä¢ Pas de charge sur le dos pendant 1 semaine\n",
    "‚Ä¢ Marche l√©g√®re uniquement\n",
    "\n",
    "**üîç CAUSES PROBABLES :**\n",
    "‚Ä¢ Technique incorrecte (genoux qui rentrent)\n",
    "‚Ä¢ Manque mobilit√© chevilles/hanches\n",
    "‚Ä¢ Core trop faible\n",
    "‚Ä¢ Progression trop rapide\n",
    "\n",
    "**ü©∫ PLAN DE R√âCUP√âRATION (2 semaines) :**\n",
    "\n",
    "**Semaine 1 - Repos actif :**\n",
    "‚Ä¢ √âtirements doux : psoas, ischio-jambiers\n",
    "‚Ä¢ Renforcement core : planche, dead bug\n",
    "‚Ä¢ Mobilit√© hanches : 10min/jour\n",
    "\n",
    "**Semaine 2 - Reprise progressive :**\n",
    "‚Ä¢ Goblet squats (poids devant) l√©gers\n",
    "‚Ä¢ Amplitude partielle puis compl√®te\n",
    "‚Ä¢ Focus TECHNIQUE avant charge\n",
    "\n",
    "**üîÑ PR√âVENTION FUTURE :**\n",
    "‚úÖ √âchauffement 10min minimum\n",
    "‚úÖ Mobilit√© quotidienne hanches/chevilles\n",
    "‚úÖ Renforcement core 3x/semaine\n",
    "‚úÖ Progression +5% max par semaine\n",
    "\n",
    "**üö® SI DOULEUR PERSISTE ‚Üí Kin√©sith√©rapeute OBLIGATOIRE**\n",
    "\n",
    "üí° **Rappel :** 2 semaines de repos > 6 mois de blessure !\"\"\"\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"input\": \"Plus motiv√©, je veux tout abandonner\",\n",
    "        \"output\": \"\"\"üî• **RECONQU√äTE MOTIVATION - STRAT√âGIE PSYCHOLOGIQUE :**\n",
    "\n",
    "**üß† R√âALIT√â CHECK :**\n",
    "‚Ä¢ La motivation FLUCTUE chez TOUT LE MONDE\n",
    "‚Ä¢ Les champions ont des jours difficiles aussi\n",
    "‚Ä¢ Les HABITUDES battent la motivation\n",
    "\n",
    "**üí™ TECHNIQUES ANTI-ABANDON :**\n",
    "\n",
    "**1. R√àGLE DES 2 MINUTES :**\n",
    "‚Ä¢ \"Je fais juste 2 pompes\"\n",
    "‚Ä¢ 90% du temps, vous continuerez !\n",
    "‚Ä¢ Maintenir l'habitude > performance\n",
    "\n",
    "**2. SYST√àME R√âCOMPENSES :**\n",
    "‚Ä¢ 1 semaine compl√®te = film/massage\n",
    "‚Ä¢ 2 semaines = nouveau v√™tement sport\n",
    "‚Ä¢ 1 mois = week-end d√©tente\n",
    "‚Ä¢ 3 mois = objectif √âNORME\n",
    "\n",
    "**3. ACCOUNTABILITY POWER :**\n",
    "‚Ä¢ Partenaire d'entra√Ænement\n",
    "‚Ä¢ Photos de progression\n",
    "‚Ä¢ Journal de victoires (m√™me petites)\n",
    "\n",
    "**4. RAPPEL PUISSANT :**\n",
    "‚Ä¢ Listez POURQUOI vous avez commenc√©\n",
    "‚Ä¢ Visualisez la version FORTE de vous-m√™me\n",
    "‚Ä¢ Vous ne regrettez JAMAIS une s√©ance faite\n",
    "\n",
    "**üèÜ MANTRA COACH :**\n",
    "\"Chaque jour, je choisis entre la version forte et faible de moi.\n",
    "Aujourd'hui, je choisis la FORCE !\"\n",
    "\n",
    "üí• **VOUS AVEZ LE POUVOIR ! REPRENEZ-LE !**\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ {len(expert_coaching_data)} exemples d'expertise coaching ajout√©s\")\n",
    "\n",
    "# === FUSION FINALE OPTIMIS√âE ===\n",
    "print(f\"\\nüîó Fusion optimis√©e des datasets...\")\n",
    "\n",
    "# V√©rification des donn√©es pars√©es\n",
    "print(f\"üîç V√©rification des donn√©es :\")\n",
    "print(f\"   ‚Ä¢ Conversations GYM pars√©es : {len(gym_enhanced_data)}\")\n",
    "print(f\"   ‚Ä¢ Expertise coaching : {len(expert_coaching_data)}\")\n",
    "\n",
    "if len(gym_enhanced_data) == 0:\n",
    "    print(f\"‚ö†Ô∏è Aucune conversation GYM pars√©e ! Utilisation expertise uniquement.\")\n",
    "    gym_sample = []\n",
    "    final_dataset = expert_coaching_data\n",
    "else:\n",
    "    # √âquilibrage intelligent : 70% GYM pars√© + 30% expertise\n",
    "    total_expert = len(expert_coaching_data)\n",
    "    target_gym_count = int(total_expert * 2.33)  # Pour ratio 70/30\n",
    "    \n",
    "    if len(gym_enhanced_data) > target_gym_count:\n",
    "        gym_sample = random.sample(gym_enhanced_data, target_gym_count)\n",
    "    else:\n",
    "        gym_sample = gym_enhanced_data\n",
    "    \n",
    "    # Fusion et m√©lange\n",
    "    final_dataset = expert_coaching_data + gym_sample\n",
    "\n",
    "random.shuffle(final_dataset)\n",
    "\n",
    "print(f\"üìä Dataset final optimis√© :\")\n",
    "print(f\"   ‚Ä¢ Expertise coaching sp√©cialis√©e : {len(expert_coaching_data)} exemples\")\n",
    "print(f\"   ‚Ä¢ GYM conversationnel am√©lior√© : {len(gym_sample)} exemples\")\n",
    "print(f\"   ‚Ä¢ TOTAL : {len(final_dataset)} exemples\")\n",
    "\n",
    "# Calcul du ratio s√©curis√©\n",
    "if len(gym_sample) > 0:\n",
    "    ratio_expertise = (len(expert_coaching_data) / len(gym_sample)) * 100\n",
    "    print(f\"   ‚Ä¢ Ratio expertise/gym : {len(expert_coaching_data)}/{len(gym_sample)} = {ratio_expertise:.0f}%/70%\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Ratio : 100% expertise (pas de donn√©es GYM pars√©es)\")\n",
    "\n",
    "# Diagnostic si probl√®me de parsing\n",
    "if len(gym_enhanced_data) == 0:\n",
    "    print(f\"\\nüîç DIAGNOSTIC PARSING :\")\n",
    "    print(f\"   ‚Ä¢ Dataset original : {len(gym_df)} lignes\")\n",
    "    print(f\"   ‚Ä¢ Parsing r√©ussi : {len(gym_parsed_data)} conversations\")\n",
    "    print(f\"   ‚Ä¢ Am√©lioration r√©ussie : {len(gym_enhanced_data)} conversations\")\n",
    "    \n",
    "    if len(gym_parsed_data) == 0:\n",
    "        print(f\"   ‚ùå Probl√®me : Aucune conversation pars√©e du format [INST]...[/INST]\")\n",
    "        print(f\"   üí° Solution : V√©rification du format des donn√©es\")\n",
    "        \n",
    "        # Affichage d'un √©chantillon pour debug\n",
    "        print(f\"\\nüìÑ √âchantillon des donn√©es brutes :\")\n",
    "        for i in range(min(2, len(gym_df))):\n",
    "            sample_text = str(gym_df.iloc[i]['text'])[:200]\n",
    "            print(f\"   Ligne {i+1}: {sample_text}...\")\n",
    "    \n",
    "    print(f\"   üí™ Pas de probl√®me ! L'expertise coaching suffit pour l'entra√Ænement.\")\n",
    "\n",
    "# === VALIDATION QUALIT√â (suite du code inchang√©e) ===\n",
    "print(f\"\\nüéØ Validation de la qualit√© :\")\n",
    "\n",
    "# Analyse des mots-cl√©s coaching\n",
    "coaching_keywords = ['coach', 'conseil', 'progression', 's√©curit√©', 'technique', 'motivation']\n",
    "keyword_coverage = 0\n",
    "\n",
    "sample_size = min(50, len(final_dataset))\n",
    "for example in final_dataset[:sample_size]:\n",
    "    response_lower = example['output'].lower()\n",
    "    if any(kw in response_lower for kw in coaching_keywords):\n",
    "        keyword_coverage += 1\n",
    "\n",
    "if sample_size > 0:\n",
    "    coverage_percentage = (keyword_coverage / sample_size) * 100\n",
    "    print(f\"   ‚Ä¢ Couverture mots-cl√©s coaching : {coverage_percentage:.0f}%\")\n",
    "    print(f\"   ‚Ä¢ Longueur moyenne r√©ponses : {np.mean([len(ex['output']) for ex in final_dataset]):.0f} caract√®res\")\n",
    "    print(f\"   ‚Ä¢ Qualit√© : {'‚úÖ Excellente' if coverage_percentage > 70 else '‚ö†Ô∏è √Ä am√©liorer'}\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Aucune donn√©e √† valider\")\n",
    "\n",
    "# Aper√ßu final\n",
    "if len(final_dataset) > 0:\n",
    "    print(f\"\\nüéØ Aper√ßu du dataset final :\")\n",
    "    for i in range(min(2, len(final_dataset))):\n",
    "        example = final_dataset[i]\n",
    "        print(f\"\\n--- Exemple {i+1} ---\")\n",
    "        print(f\"‚ùì Question: {example['input'][:70]}...\")\n",
    "        print(f\"ü§ñ R√©ponse: {example['output'][:120]}...\")\n",
    "\n",
    "    print(f\"\\n‚úÖ CELLULE 1 TERMIN√âE - Dataset conversationnel pr√™t pour l'entra√Ænement !\")\n",
    "    print(f\"üéØ {len(final_dataset)} exemples de coaching de haute qualit√© pr√©par√©s\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå PROBL√àME : Dataset final vide\")\n",
    "    print(f\"üí° V√©rifiez le parsing ou utilisez uniquement l'expertise coaching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLULE 2 : CONFIGURATION ET ENTRA√éNEMENT MT5\n",
    "# ============================================================================\n",
    "\n",
    "print(\"ü§ñ CELLULE 2 : Configuration et entra√Ænement MT5\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# === PR√âPARATION POUR MT5 ===\n",
    "print(\"\\nüîÑ Pr√©paration des donn√©es pour MT5...\")\n",
    "\n",
    "def create_mt5_prompts(dataset):\n",
    "    \"\"\"Cr√©e des prompts optimis√©s pour MT5\"\"\"\n",
    "    mt5_dataset = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        # Prompt structur√© pour MT5 avec pr√©fixe coaching\n",
    "        mt5_prompt = f\"coach fitness expert: {example['input']}\"\n",
    "        \n",
    "        mt5_dataset.append({\n",
    "            \"input\": mt5_prompt,\n",
    "            \"output\": example['output']\n",
    "        })\n",
    "    \n",
    "    return mt5_dataset\n",
    "\n",
    "# Conversion des donn√©es\n",
    "mt5_dataset = create_mt5_prompts(final_dataset)\n",
    "\n",
    "# Division train/validation stratifi√©e\n",
    "train_data, val_data = train_test_split(mt5_dataset, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"üìä Donn√©es MT5 pr√©par√©es :\")\n",
    "print(f\"   ‚Ä¢ Entra√Ænement : {len(train_data)} exemples\")\n",
    "print(f\"   ‚Ä¢ Validation : {len(val_data)} exemples\")\n",
    "\n",
    "# V√©rification de la qualit√© des donn√©es\n",
    "if len(train_data) < 10:\n",
    "    print(f\"‚ö†Ô∏è Dataset petit ({len(train_data)} exemples d'entra√Ænement)\")\n",
    "    print(f\"üí° L'entra√Ænement sera rapide mais moins robuste\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset suffisant pour un bon entra√Ænement\")\n",
    "\n",
    "# === CHARGEMENT MOD√àLE MT5 ===\n",
    "print(f\"\\nü§ñ Chargement du mod√®le MT5...\")\n",
    "\n",
    "model_name = \"google/mt5-base\"\n",
    "try:\n",
    "    tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
    "    model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    print(f\"‚úÖ Mod√®le {model_name} charg√© avec succ√®s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur chargement mod√®le : {e}\")\n",
    "    print(f\"üí° V√©rifiez votre connexion internet\")\n",
    "    raise\n",
    "\n",
    "# Param√®tres optimis√©s pour coaching\n",
    "max_input_length = 512\n",
    "max_target_length = 400  # Plus long pour r√©ponses d√©taill√©es\n",
    "\n",
    "print(f\"‚öôÔ∏è Configuration :\")\n",
    "print(f\"   ‚Ä¢ Input max : {max_input_length} tokens\")\n",
    "print(f\"   ‚Ä¢ Output max : {max_target_length} tokens\")\n",
    "print(f\"   ‚Ä¢ Device : {device}\")\n",
    "\n",
    "# Transfert du mod√®le sur le device appropri√©\n",
    "model.to(device)\n",
    "print(f\"‚úÖ Mod√®le transf√©r√© sur {device}\")\n",
    "\n",
    "# === PR√âPROCESSING POUR ENTRA√éNEMENT ===\n",
    "print(f\"\\nüîÑ Configuration du preprocessing...\")\n",
    "\n",
    "def preprocess_mt5_coaching(examples):\n",
    "    \"\"\"Pr√©processing optimis√© pour coaching MT5\"\"\"\n",
    "    \n",
    "    inputs = examples[\"input\"]\n",
    "    targets = examples[\"output\"]\n",
    "    \n",
    "    # Tokenisation inputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Tokenisation targets\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Conversion en datasets Hugging Face\n",
    "print(\"üîÑ Tokenisation des donn√©es...\")\n",
    "try:\n",
    "    train_dataset = Dataset.from_pandas(pd.DataFrame(train_data))\n",
    "    val_dataset = Dataset.from_pandas(pd.DataFrame(val_data))\n",
    "    \n",
    "    tokenized_train = train_dataset.map(preprocess_mt5_coaching, batched=True)\n",
    "    tokenized_val = val_dataset.map(preprocess_mt5_coaching, batched=True)\n",
    "    print(\"‚úÖ Tokenisation termin√©e\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur tokenisation : {e}\")\n",
    "    raise\n",
    "\n",
    "# === CONFIGURATION ENTRA√éNEMENT ===\n",
    "print(\"\\n‚öôÔ∏è Configuration de l'entra√Ænement...\")\n",
    "\n",
    "# Arguments d'entra√Ænement optimis√©s pour coaching\n",
    "# Adaptation selon la taille du dataset\n",
    "if len(train_data) < 50:\n",
    "    # Dataset tr√®s petit\n",
    "    num_epochs = 8\n",
    "    batch_size = 1\n",
    "    eval_steps = 10\n",
    "    save_steps = 20\n",
    "    warmup_steps = 5\n",
    "    print(\"üìä Configuration adapt√©e : Dataset tr√®s petit\")\n",
    "elif len(train_data) < 200:\n",
    "    # Dataset petit\n",
    "    num_epochs = 6\n",
    "    batch_size = 2\n",
    "    eval_steps = 25\n",
    "    save_steps = 50\n",
    "    warmup_steps = 20\n",
    "    print(\"üìä Configuration adapt√©e : Dataset petit\")\n",
    "else:\n",
    "    # Dataset standard\n",
    "    num_epochs = 4\n",
    "    batch_size = 2\n",
    "    eval_steps = 100\n",
    "    save_steps = 200\n",
    "    warmup_steps = 100\n",
    "    print(\"üìä Configuration adapt√©e : Dataset standard\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mt5-expert-fitness-coach\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=3e-5,  # Learning rate optimal pour fine-tuning\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=max(10, len(train_data) // 10),  # Adaptatif\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    gradient_accumulation_steps=max(1, 4 // batch_size),  # Simule batch_size plus grand\n",
    "    fp16=torch.cuda.is_available(),  # Optimisation GPU si disponible\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,  # D√©sactive wandb\n",
    "    disable_tqdm=False,  # Affichage des barres de progression\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Configuration termin√©e :\")\n",
    "print(f\"   ‚Ä¢ √âpoques : {training_args.num_train_epochs}\")\n",
    "print(f\"   ‚Ä¢ Batch size : {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   ‚Ä¢ Learning rate : {training_args.learning_rate}\")\n",
    "print(f\"   ‚Ä¢ Gradient accumulation : {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"   ‚Ä¢ √âvaluation toutes les {training_args.eval_steps} √©tapes\")\n",
    "\n",
    "# Data collator\n",
    "try:\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=True\n",
    "    )\n",
    "    print(\"‚úÖ Data collator configur√©\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur data collator : {e}\")\n",
    "    raise\n",
    "\n",
    "# === INITIALISATION TRAINER ===\n",
    "print(f\"\\nüèãÔ∏è Initialisation du Trainer...\")\n",
    "\n",
    "try:\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    print(\"‚úÖ Trainer configur√© et pr√™t\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur configuration Trainer : {e}\")\n",
    "    raise\n",
    "\n",
    "# Estimation du temps d'entra√Ænement\n",
    "steps_per_epoch = len(tokenized_train) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\n",
    "total_steps = steps_per_epoch * training_args.num_train_epochs\n",
    "estimated_time_gpu = total_steps * 2 / 60  # ~2 secondes par step sur GPU\n",
    "estimated_time_cpu = total_steps * 10 / 60  # ~10 secondes par step sur CPU\n",
    "\n",
    "print(f\"\\nüìä Estimation entra√Ænement :\")\n",
    "print(f\"   ‚Ä¢ Steps par √©poque : {steps_per_epoch}\")\n",
    "print(f\"   ‚Ä¢ Steps total : {total_steps}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   ‚Ä¢ Temps estim√© (GPU) : {estimated_time_gpu:.1f} minutes\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Temps estim√© (CPU) : {estimated_time_cpu:.1f} minutes\")\n",
    "\n",
    "# === ENTRA√éNEMENT ===\n",
    "print(f\"\\nüöÄ D√âBUT DE L'ENTRA√éNEMENT DU COACH EXPERT\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚è±Ô∏è L'entra√Ænement va commencer...\")\n",
    "print(\"üí° Surveillez eval_loss : doit diminuer progressivement\")\n",
    "print(\"üîÑ Vous pouvez interrompre avec Ctrl+C si n√©cessaire\")\n",
    "\n",
    "try:\n",
    "    # Lancement de l'entra√Ænement\n",
    "    trainer.train()\n",
    "    print(\"\\nüéâ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS !\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è Entra√Ænement interrompu par l'utilisateur\")\n",
    "    print(\"üíæ Sauvegarde du mod√®le en cours d'entra√Ænement...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erreur pendant l'entra√Ænement : {e}\")\n",
    "    print(\"üíæ Tentative de sauvegarde...\")\n",
    "\n",
    "# === SAUVEGARDE ===\n",
    "print(f\"\\nüíæ Sauvegarde du mod√®le expert...\")\n",
    "\n",
    "model_save_path = \"./mt5-expert-fitness-coach\"\n",
    "\n",
    "try:\n",
    "    # Cr√©ation du dossier si n√©cessaire\n",
    "    Path(model_save_path).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Sauvegarde du mod√®le et tokenizer\n",
    "    trainer.save_model(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    \n",
    "    # Configuration de l'entra√Ænement\n",
    "    training_config = {\n",
    "        \"model_name\": \"mt5-expert-fitness-coach\",\n",
    "        \"base_model\": \"google/mt5-base\",\n",
    "        \"training_examples\": len(train_data),\n",
    "        \"validation_examples\": len(val_data),\n",
    "        \"total_examples\": len(final_dataset),\n",
    "        \"max_input_length\": max_input_length,\n",
    "        \"max_target_length\": max_target_length,\n",
    "        \"epochs\": training_args.num_train_epochs,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"training_date\": pd.Timestamp.now().isoformat(),\n",
    "        \"device_used\": str(device),\n",
    "        \"performance_notes\": \"Coach expert avec dataset conversationnel + expertise professionnelle\"\n",
    "    }\n",
    "    \n",
    "    with open(f\"{model_save_path}/training_config.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(training_config, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le expert sauvegard√© dans : {model_save_path}\")\n",
    "    print(\"‚úÖ Configuration sauvegard√©e\")\n",
    "    \n",
    "    # Affichage du chemin absolu pour r√©f√©rence\n",
    "    absolute_path = Path(model_save_path).resolve()\n",
    "    print(f\"üìÅ Chemin absolu : {absolute_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur sauvegarde : {e}\")\n",
    "\n",
    "# === V√âRIFICATION POST-ENTRA√éNEMENT ===\n",
    "print(f\"\\nüîç V√©rification post-entra√Ænement...\")\n",
    "\n",
    "# V√©rification des fichiers sauvegard√©s\n",
    "expected_files = [\"config.json\", \"pytorch_model.bin\", \"tokenizer.json\", \"training_config.json\"]\n",
    "missing_files = []\n",
    "\n",
    "for file in expected_files:\n",
    "    file_path = Path(model_save_path) / file\n",
    "    if file_path.exists():\n",
    "        file_size = file_path.stat().st_size / (1024*1024)  # MB\n",
    "        print(f\"   ‚úÖ {file} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        missing_files.append(file)\n",
    "        print(f\"   ‚ùå {file} manquant\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"‚ö†Ô∏è Fichiers manquants : {missing_files}\")\n",
    "    print(f\"üí° L'entra√Ænement a peut-√™tre √©t√© interrompu\")\n",
    "else:\n",
    "    print(f\"‚úÖ Tous les fichiers essentiels pr√©sents\")\n",
    "\n",
    "print(f\"\\n‚úÖ CELLULE 2 TERMIN√âE - Mod√®le expert entra√Æn√© et sauvegard√© !\")\n",
    "print(f\"üéØ Pr√™t pour les tests et l'export Django (Cellule 3)\")\n",
    "\n",
    "message.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
