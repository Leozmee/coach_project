{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"onurSakar/GYM-Exercise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: evaluate in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: accelerate in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: filelock in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: psutil in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from accelerate) (2.7.1+cu118)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: setuptools in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Chatbot Coach Sportif en Français avec mT5-small (FP16, batch_size ≤ 4)\n",
    "#\n",
    "# Ce notebook présente le fine‑tuning de **mT5-small** en précision mixte (FP16) avec un batch size maximal de 4.\n",
    "# Optimisé pour un GPU 3060 Laptop (6 Go VRAM) \n",
    "\n",
    "\n",
    "# 1) Installation et imports\n",
    "%pip install transformers datasets evaluate accelerate\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: [],\n",
      "        num_rows: 0\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: [],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#2) Chargement et exploration des données\n",
    "\n",
    "# Chargement du split 'train' et découpes en train/validation\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "cols = ['EXERCISE_NAME','EXERCISE_TYPE','MUSCLES_PRIMARY','EQUIPMENT']\n",
    "raw = raw.remove_columns([c for c in raw.column_names if c not in cols])\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    'train': split['train'],\n",
    "    'validation': split['test'],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.mt5.tokenization_mt5.MT5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Column name ['MUSCLES_PRIMARY', 'EQUIPMENT', 'EXERCISE_TYPE', 'EXERCISE_NAME'] not in the dataset. Current columns in the dataset: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     32\u001b[39m tokenized_val = datasets[\u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m].map(\n\u001b[32m     33\u001b[39m     preprocess_examples,\n\u001b[32m     34\u001b[39m     batched=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Supprimer colonnes d'origine\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m tokenized_train = \u001b[43mtokenized_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m tokenized_val   = tokenized_val.remove_columns(cols)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Conversion en format PyTorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2161\u001b[39m, in \u001b[36mDataset.remove_columns\u001b[39m\u001b[34m(self, column_names, new_fingerprint)\u001b[39m\n\u001b[32m   2159\u001b[39m missing_columns = \u001b[38;5;28mset\u001b[39m(column_names) - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.column_names)\n\u001b[32m   2160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset._data.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2164\u001b[39m     )\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[32m   2167\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m dataset._info.features[column_name]\n",
      "\u001b[31mValueError\u001b[39m: Column name ['MUSCLES_PRIMARY', 'EQUIPMENT', 'EXERCISE_TYPE', 'EXERCISE_NAME'] not in the dataset. Current columns in the dataset: []"
     ]
    }
   ],
   "source": [
    "\n",
    "#Pré‑traitement & Tokenisation\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_length, max_target_length = 128, 64\n",
    "\n",
    "def preprocess_examples(examples):\n",
    "    inputs = [\n",
    "        f\"Question: Explique l'exercice {name} pour cibler {muscles}. Type: {type_}, équipement: {eq}.\"\n",
    "        for name, muscles, type_, eq in zip(\n",
    "            examples['EXERCISE_NAME'], examples['MUSCLES_PRIMARY'],\n",
    "            examples['EXERCISE_TYPE'], examples['EQUIPMENT']\n",
    "        )\n",
    "    ]\n",
    "    targets = [f\"Réponse: Voici comment réaliser {name}...\" for name in examples['EXERCISE_NAME']]\n",
    "\n",
    "    tokenized_inputs = tokenizer(\n",
    "        inputs, max_length=max_input_length, truncation=True, padding='max_length'\n",
    "    )\n",
    "    tokenized_targets = tokenizer(\n",
    "        targets, max_length=max_target_length, truncation=True, padding='max_length'\n",
    "    )\n",
    "    tokenized_inputs['labels'] = tokenized_targets['input_ids']\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Map train\n",
    "tokenized_train = datasets['train'].map(\n",
    "    preprocess_examples,\n",
    "    batched=True,\n",
    ")\n",
    "# Map validation\n",
    "tokenized_val = datasets['validation'].map(\n",
    "    preprocess_examples,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Supprimer colonnes d'origine\n",
    "tokenized_train = tokenized_train.remove_columns(cols)\n",
    "tokenized_val   = tokenized_val.remove_columns(cols)\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "tokenized_val.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "# Reconstruction du DatasetDict tokenisé\n",
    "from datasets import DatasetDict as _DatasetDict\n",
    "tokenized = _DatasetDict({\n",
    "    'train': tokenized_train,\n",
    "    'validation': tokenized_val,\n",
    "})\n",
    "\n",
    "# Data collator pour Seq2Seq\n",
    "from transformers import DataCollatorForSeq2Seq as _DataCollatorForSeq2Seq\n",
    "data_collator = _DataCollatorForSeq2Seq(tokenizer, model=None)\n",
    "tokenized = DatasetDict({\n",
    "    'train': tokenized_train,\n",
    "    'validation': tokenized_val,\n",
    "})\n",
    "\n",
    "# Data collator pour Seq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None, return_tensors='pt')(tokenizer, model=None, return_tensors='pt')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4) Fine‑tuning mT5-small\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",   # dossier de checkpoints\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    predict_with_generate=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_steps=200,\n",
    "    do_eval=True,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,      # conserver toutes les colonnes utiles\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],  # assurez-vous que ces splits existent\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Lancement de l'entraînement\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference : exemples de génération\n",
    "\n",
    "prompts = [\n",
    "    \"Question: Explique l'exercice Bench Press pour cibler pectoraux. Type: Strength, équipement: Barbell.\",\n",
    "    \"Question: Décris l'exercice Squat pour les quadriceps. Type: Strength, équipement: Bodyweight.\",\n",
    "]\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_length)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation\n",
    "\n",
    "import math\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"perplexity\", module_type=\"metrics\")\n",
    "\n",
    "results = trainer.predict(tokenized['validation'])\n",
    "perplexity = math.exp(results.metrics['eval_loss'])\n",
    "print(f\"Perplexité (valid): {perplexity:.2f}\")\n",
    "\n",
    "# Prompt → attendu vs généré\n",
    "for ex in datasets['validation'].shuffle(seed=1).select(range(5)):\n",
    "    prompt = f\"Question: Explique l'exercice {ex['EXERCISE_NAME']} pour cibler {ex['MUSCLES_PRIMARY']}.\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    gen_ids = model.generate(input_ids, max_length=64)\n",
    "    print(\"\\nPrompt:\", prompt)\n",
    "    print(\"Attendu:\", f\"Réponse: Voici comment réaliser {ex['EXERCISE_NAME']}...\")\n",
    "    print(\"Généré:\", tokenizer.decode(gen_ids[0], skip_special_tokens=True))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7) Visualisation des métriques\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "logs = trainer.state.log_history\n",
    "train_loss = [x['loss'] for x in logs if 'loss' in x and x.get('epoch')]\n",
    "eval_loss  = [x['eval_loss'] for x in logs if 'eval_loss' in x]\n",
    "epochs     = sorted(set([x['epoch'] for x in logs if 'loss' in x]))\n",
    "eval_epochs= sorted(set([x['epoch'] for x in logs if 'eval_loss' in x]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.plot(eval_epochs, eval_loss, label='Eval Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Courbe de Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns ['attention_mask', 'input_ids', 'labels'] not in the dataset. Current columns in the dataset: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     23\u001b[39m tokenized = datasets.map(\n\u001b[32m     24\u001b[39m     preprocess_examples,\n\u001b[32m     25\u001b[39m     batched=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     26\u001b[39m     remove_columns=datasets[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].column_names\n\u001b[32m     27\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Convertir en format PyTorch pour le DataLoader\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mtokenized\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m data_collator = DataCollatorForSeq2Seq(tokenizer, model=\u001b[38;5;28;01mNone\u001b[39;00m, return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/dataset_dict.py:613\u001b[39m, in \u001b[36mDatasetDict.set_format\u001b[39m\u001b[34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28mself\u001b[39m._check_values_type()\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values():\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2538\u001b[39m, in \u001b[36mDataset.set_format\u001b[39m\u001b[34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[39m\n\u001b[32m   2536\u001b[39m     missing_columns = \u001b[38;5;28mset\u001b[39m(columns) - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.column_names)\n\u001b[32m   2537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2538\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2539\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._data.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2540\u001b[39m         )\n\u001b[32m   2541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2542\u001b[39m     columns = columns.copy()  \u001b[38;5;66;03m# Ensures modifications made to the list after this call don't cause bugs\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Columns ['attention_mask', 'input_ids', 'labels'] not in the dataset. Current columns in the dataset: []"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3) Pré‑traitement & Tokenisation\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_length, max_target_length = 128, 64\n",
    "\n",
    "def preprocess_examples(examples):\n",
    "    inputs = [\n",
    "        f\"Question: Explique l'exercice {name} pour cibler {muscles}. Type: {type_}, équipement: {eq}.\"\n",
    "        for name, muscles, type_, eq in zip(\n",
    "            examples['EXERCISE_NAME'], examples['MUSCLES_PRIMARY'],\n",
    "            examples['EXERCISE_TYPE'], examples['EQUIPMENT']\n",
    "        )\n",
    "    ]\n",
    "    targets = [f\"Réponse: Voici comment réaliser {name}...\" for name in examples['EXERCISE_NAME']]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = datasets.map(\n",
    "    preprocess_examples,\n",
    "    batched=True,\n",
    "    remove_columns=datasets['train'].column_names\n",
    ")\n",
    "# Convertir en format PyTorch pour le DataLoader\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None, return_tensors='pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4) Fine‑tuning mT5-small\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",   # dossier de checkpoints\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    predict_with_generate=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_steps=200,\n",
    "    do_eval=True,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,      # conserver toutes les colonnes utiles\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],  # assurez-vous que ces splits existent\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Lancement de l'entraînement\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference : exemples de génération\n",
    "\n",
    "prompts = [\n",
    "    \"Question: Explique l'exercice Bench Press pour cibler pectoraux. Type: Strength, équipement: Barbell.\",\n",
    "    \"Question: Décris l'exercice Squat pour les quadriceps. Type: Strength, équipement: Bodyweight.\",\n",
    "]\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_length)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation\n",
    "\n",
    "import math\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"perplexity\", module_type=\"metrics\")\n",
    "\n",
    "results = trainer.predict(tokenized['validation'])\n",
    "perplexity = math.exp(results.metrics['eval_loss'])\n",
    "print(f\"Perplexité (valid): {perplexity:.2f}\")\n",
    "\n",
    "# Prompt → attendu vs généré\n",
    "for ex in datasets['validation'].shuffle(seed=1).select(range(5)):\n",
    "    prompt = f\"Question: Explique l'exercice {ex['EXERCISE_NAME']} pour cibler {ex['MUSCLES_PRIMARY']}.\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    gen_ids = model.generate(input_ids, max_length=64)\n",
    "    print(\"\\nPrompt:\", prompt)\n",
    "    print(\"Attendu:\", f\"Réponse: Voici comment réaliser {ex['EXERCISE_NAME']}...\")\n",
    "    print(\"Généré:\", tokenizer.decode(gen_ids[0], skip_special_tokens=True))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7) Visualisation des métriques\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "logs = trainer.state.log_history\n",
    "train_loss = [x['loss'] for x in logs if 'loss' in x and x.get('epoch')]\n",
    "eval_loss  = [x['eval_loss'] for x in logs if 'eval_loss' in x]\n",
    "epochs     = sorted(set([x['epoch'] for x in logs if 'loss' in x]))\n",
    "eval_epochs= sorted(set([x['epoch'] for x in logs if 'eval_loss' in x]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.plot(eval_epochs, eval_loss, label='Eval Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Courbe de Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: [],\n",
      "        num_rows: 0\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: [],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenisation…\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Column name ['EQUIPMENT', 'EXERCISE_TYPE', 'EXERCISE_NAME', 'MUSCLES_PRIMARY'] not in the dataset. Current columns in the dataset: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Tokenisation des deux splits\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTokenisation…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m train_tok = \u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcols_keep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m val_tok   = datasets[\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m].map(preprocess, batched=\u001b[38;5;28;01mTrue\u001b[39;00m, remove_columns=cols_keep)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Conversion en tensors PyTorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2976\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   2969\u001b[39m     \u001b[38;5;28mself\u001b[39m = Dataset(\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28mself\u001b[39m.data.slice(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m),\n\u001b[32m   2971\u001b[39m         info=\u001b[38;5;28mself\u001b[39m.info.copy(),\n\u001b[32m   2972\u001b[39m         split=\u001b[38;5;28mself\u001b[39m.split,\n\u001b[32m   2973\u001b[39m         fingerprint=new_fingerprint,\n\u001b[32m   2974\u001b[39m     )\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remove_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2161\u001b[39m, in \u001b[36mDataset.remove_columns\u001b[39m\u001b[34m(self, column_names, new_fingerprint)\u001b[39m\n\u001b[32m   2159\u001b[39m missing_columns = \u001b[38;5;28mset\u001b[39m(column_names) - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.column_names)\n\u001b[32m   2160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset._data.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2164\u001b[39m     )\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[32m   2167\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m dataset._info.features[column_name]\n",
      "\u001b[31mValueError\u001b[39m: Column name ['EQUIPMENT', 'EXERCISE_TYPE', 'EXERCISE_NAME', 'MUSCLES_PRIMARY'] not in the dataset. Current columns in the dataset: []"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Chatbot Coach Sportif en Français avec **mT5‑small** (FP16, batch ≤ 4)\n",
    "#\n",
    "# Ce notebook montre comment fine‑tuner **google/mt5‑small** pour générer des réponses de coaching sportif en français à partir du dataset **onurSakar/GYM‑Exercise**.\n",
    "# Paramètres pensés pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "#\n",
    "# **Plan :**\n",
    "# 1. Installation & imports  \n",
    "# 2. Préparation du dataset (split train/validation)  \n",
    "# 3. Tokenisation  \n",
    "# 4. Fine‑tuning  \n",
    "# 5. Inference & évaluation  \n",
    "# 6. Visualisation des métriques\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "%pip install -q transformers datasets evaluate accelerate\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math, random\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Chargement et découpe des données\n",
    "\n",
    "# On ne dispose que d'un split \"train\" → on crée validation manuellement\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "cols_keep = [\"EXERCISE_NAME\",\"EXERCISE_TYPE\",\"MUSCLES_PRIMARY\",\"EQUIPMENT\"]\n",
    "raw = raw.remove_columns([c for c in raw.column_names if c not in cols_keep])\n",
    "\n",
    "# Sous‑échantillonnage : 600 exemples (500 train / 100 val) pour une démo rapide\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "split = raw.train_test_split(test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3) Pré‑traitement & tokenisation\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_len, max_target_len = 128, 64\n",
    "\n",
    "prompt_tpl  = (\n",
    "    \"Question : Explique l'exercice {name} pour cibler {muscles}. \"\n",
    "    \"Type : {type}, équipement : {eq}.\"\n",
    ")\n",
    "answer_tpl  = \"Réponse : Voici comment réaliser {name} :\"\n",
    "\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs   = [prompt_tpl.format(name=n, muscles=m, type=t, eq=e)\n",
    "                for n, m, t, e in zip(batch[\"EXERCISE_NAME\"], batch[\"MUSCLES_PRIMARY\"],\n",
    "                                      batch[\"EXERCISE_TYPE\"], batch[\"EQUIPMENT\"])]\n",
    "    targets  = [answer_tpl.format(name=n) for n in batch[\"EXERCISE_NAME\"]]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_len, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_len, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenisation des deux splits\n",
    "print(\"Tokenisation…\")\n",
    "train_tok = datasets[\"train\"].map(preprocess, batched=True, remove_columns=cols_keep)\n",
    "val_tok   = datasets[\"validation\"].map(preprocess, batched=True, remove_columns=cols_keep)\n",
    "\n",
    "# Conversion en tensors PyTorch\n",
    "train_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "val_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "tokenized = DatasetDict({\"train\": train_tok, \"validation\": val_tok})\n",
    "print(tokenized)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4) Fine‑tuning\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference rapide\n",
    "\n",
    "prompts = [\n",
    "    \"Question : Explique l'exercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\",\n",
    "    \"Question : Décris l'exercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_len).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\n\\nGénérations :\")\n",
    "print(*tokenizer.batch_decode(outputs, skip_special_tokens=True), sep=\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation & visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perplexité de validation\n",
    "val_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"Perplexité validation : {perplexity:.2f}\")\n",
    "\n",
    "# Courbes de loss\n",
    "train_logs = [l for l in trainer.state.log_history if \"loss\" in l and l.get(\"epoch\") is not None]\n",
    "train_epochs = [l[\"epoch\"] for l in train_logs]\n",
    "train_losses = [l[\"loss\"] for l in train_logs]\n",
    "\n",
    "eval_logs = [l for l in trainer.state.log_history if \"eval_loss\" in l]\n",
    "eval_epochs = [l[\"epoch\"] for l in eval_logs]\n",
    "eval_losses = [l[\"eval_loss\"] for l in eval_logs]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, train_losses, label=\"Train loss\")\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: [],\n",
      "        num_rows: 0\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: [],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Column name ['target_text', 'text', 'input_text'] not in the dataset. Current columns in the dataset: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m     enc[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m] = labels[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m enc\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m train_tok = \u001b[43msplit_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m val_tok   = split_val.map(preprocess, batched=\u001b[38;5;28;01mTrue\u001b[39;00m, remove_columns=[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33minput_text\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mtarget_text\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Conversion en format PyTorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2976\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   2969\u001b[39m     \u001b[38;5;28mself\u001b[39m = Dataset(\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28mself\u001b[39m.data.slice(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m),\n\u001b[32m   2971\u001b[39m         info=\u001b[38;5;28mself\u001b[39m.info.copy(),\n\u001b[32m   2972\u001b[39m         split=\u001b[38;5;28mself\u001b[39m.split,\n\u001b[32m   2973\u001b[39m         fingerprint=new_fingerprint,\n\u001b[32m   2974\u001b[39m     )\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remove_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2161\u001b[39m, in \u001b[36mDataset.remove_columns\u001b[39m\u001b[34m(self, column_names, new_fingerprint)\u001b[39m\n\u001b[32m   2159\u001b[39m missing_columns = \u001b[38;5;28mset\u001b[39m(column_names) - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.column_names)\n\u001b[32m   2160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset._data.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2164\u001b[39m     )\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[32m   2167\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m dataset._info.features[column_name]\n",
      "\u001b[31mValueError\u001b[39m: Column name ['target_text', 'text', 'input_text'] not in the dataset. Current columns in the dataset: []"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Chatbot Coach Sportif en Français avec **mT5‑small** (FP16, batch ≤ 4)\n",
    "#\n",
    "# Ce notebook montre comment fine‑tuner **google/mt5‑small** pour générer des réponses de coaching sportif en français à partir du dataset **onurSakar/GYM‑Exercise**.\n",
    "# Paramètres pensés pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "#\n",
    "# **Plan :**\n",
    "# 1. Installation & imports  \n",
    "# 2. Préparation du dataset (split train/validation)  \n",
    "# 3. Tokenisation  \n",
    "# 4. Fine‑tuning  \n",
    "# 5. Inference & évaluation  \n",
    "# 6. Visualisation des métriques\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math, random\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Chargement et découpe des données\n",
    "\n",
    "# On ne dispose que d'un split \"train\" → on crée validation manuellement\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "cols_keep = [\"EXERCISE_NAME\",\"EXERCISE_TYPE\",\"MUSCLES_PRIMARY\",\"EQUIPMENT\"]\n",
    "raw = raw.remove_columns([c for c in raw.column_names if c not in cols_keep])\n",
    "\n",
    "# Sous‑échantillonnage : 600 exemples (500 train / 100 val) pour une démo rapide\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "split = raw.train_test_split(test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3) Pré‑traitement & tokenisation\n",
    "\n",
    "# On parse la colonne 'text' pour extraire question et réponse\n",
    "import re\n",
    "\n",
    "def split_instruction_response(example):\n",
    "    text = example['text']\n",
    "    # Séparer instruction et réponse\n",
    "    parts = text.split(\"[/INST]\")\n",
    "    if len(parts) != 2:\n",
    "        return {\"input_text\": \"\", \"target_text\": \"\"}\n",
    "    instr_part, ans_part = parts\n",
    "    # Extraire la question après la balise de fin du SYS\n",
    "    question = instr_part.split(\"<</SYS>>\")[-1].strip()\n",
    "    # Nettoyer la réponse (enlever balises)</n    answer = ans_part.replace(\"</s>\", \"\").strip()\n",
    "    return {\"input_text\": question, \"target_text\": answer}\n",
    "\n",
    "# Appliquer le split sur les datasets bruts\n",
    "split_train = datasets['train'].map(split_instruction_response)\n",
    "split_val   = datasets['validation'].map(split_instruction_response)\n",
    "\n",
    "# Tokenisation\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_len, max_target_len = 128, 64\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Tokenize inputs\n",
    "    enc = tokenizer(batch['input_text'], max_length=max_input_len,\n",
    "                    truncation=True, padding='max_length')\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch['target_text'], max_length=max_target_len,\n",
    "                           truncation=True, padding='max_length')\n",
    "    enc['labels'] = labels['input_ids']\n",
    "    return enc\n",
    "\n",
    "train_tok = split_train.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "val_tok   = split_val.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "train_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "tokenized = DatasetDict({'train': train_tok, 'validation': val_tok})\n",
    "print(tokenized)\n",
    "\n",
    "## 4) Fine‑tuning\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference rapide\n",
    "\n",
    "prompts = [\n",
    "    \"Question : Explique l'exercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\",\n",
    "    \"Question : Décris l'exercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_len).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\n\\nGénérations :\")\n",
    "print(*tokenizer.batch_decode(outputs, skip_special_tokens=True), sep=\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation & visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perplexité de validation\n",
    "val_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"Perplexité validation : {perplexity:.2f}\")\n",
    "\n",
    "# Courbes de loss\n",
    "train_logs = [l for l in trainer.state.log_history if \"loss\" in l and l.get(\"epoch\") is not None]\n",
    "train_epochs = [l[\"epoch\"] for l in train_logs]\n",
    "train_losses = [l[\"loss\"] for l in train_logs]\n",
    "\n",
    "eval_logs = [l for l in trainer.state.log_history if \"eval_loss\" in l]\n",
    "eval_epochs = [l[\"epoch\"] for l in eval_logs]\n",
    "eval_losses = [l[\"eval_loss\"] for l in eval_logs]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, train_losses, label=\"Train loss\")\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/500 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33minput_text\u001b[39m\u001b[33m\"\u001b[39m: question, \u001b[33m\"\u001b[39m\u001b[33mtarget_text\u001b[39m\u001b[33m\"\u001b[39m: answer}\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Appliquer le split sur les datasets bruts\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m split_train = \u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_instruction_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m split_val   = datasets[\u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m].map(split_instruction_response)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Tokenisation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3079\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   3073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3074\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3075\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3076\u001b[39m         total=pbar_total,\n\u001b[32m   3077\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3078\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3501\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[39m\n\u001b[32m   3499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3500\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3501\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3502\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3503\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3475\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3473\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3474\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3475\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3398\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3397\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3398\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36msplit_instruction_response\u001b[39m\u001b[34m(example)\u001b[39m\n\u001b[32m     54\u001b[39m question = instr_part.split(\u001b[33m\"\u001b[39m\u001b[33m<</SYS>>\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m].strip()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Nettoyer la réponse (enlever balises)</n    answer = ans_part.replace(\"</s>\", \"\").strip()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33minput_text\u001b[39m\u001b[33m\"\u001b[39m: question, \u001b[33m\"\u001b[39m\u001b[33mtarget_text\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43manswer\u001b[49m}\n",
      "\u001b[31mNameError\u001b[39m: name 'answer' is not defined"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Chatbot Coach Sportif en Français avec **mT5‑small** (FP16, batch ≤ 4)\n",
    "#\n",
    "# Ce notebook montre comment fine‑tuner **google/mt5‑small** pour générer des réponses de coaching sportif en français à partir du dataset **onurSakar/GYM‑Exercise**.\n",
    "# Paramètres pensés pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "#\n",
    "# **Plan :**\n",
    "# 1. Installation & imports  \n",
    "# 2. Préparation du dataset (split train/validation)  \n",
    "# 3. Tokenisation  \n",
    "# 4. Fine‑tuning  \n",
    "# 5. Inference & évaluation  \n",
    "# 6. Visualisation des métriques\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "%pip install -q transformers datasets evaluate accelerate\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math, random\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Chargement et découpe des données\n",
    "\n",
    "# Le dataset ne contient qu'une seule colonne 'text' (instruction + réponse)\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "# Sous-échantillonnage : 600 exemples pour une démo rapide (500 train / 100 val)\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "# Split en train et validation\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "## 3) Pré‑traitement & tokenisation Pré‑traitement & tokenisation\n",
    "\n",
    "# On parse la colonne 'text' pour extraire question et réponse\n",
    "import re\n",
    "\n",
    "def split_instruction_response(example):\n",
    "    text = example['text']\n",
    "    # Séparer instruction et réponse\n",
    "    parts = text.split(\"[/INST]\")\n",
    "    if len(parts) != 2:\n",
    "        return {\"input_text\": \"\", \"target_text\": \"\"}\n",
    "    instr_part, ans_part = parts\n",
    "    # Extraire la question après la balise de fin du SYS\n",
    "    question = instr_part.split(\"<</SYS>>\")[-1].strip()\n",
    "    # Nettoyer la réponse (enlever balises)</n    answer = ans_part.replace(\"</s>\", \"\").strip()\n",
    "    return {\"input_text\": question, \"target_text\": answer}\n",
    "\n",
    "# Appliquer le split sur les datasets bruts\n",
    "split_train = datasets['train'].map(split_instruction_response)\n",
    "split_val   = datasets['validation'].map(split_instruction_response)\n",
    "\n",
    "# Tokenisation\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_len, max_target_len = 128, 64\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Tokenize inputs\n",
    "    enc = tokenizer(batch['input_text'], max_length=max_input_len,\n",
    "                    truncation=True, padding='max_length')\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch['target_text'], max_length=max_target_len,\n",
    "                           truncation=True, padding='max_length')\n",
    "    enc['labels'] = labels['input_ids']\n",
    "    return enc\n",
    "\n",
    "train_tok = split_train.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "val_tok   = split_val.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "train_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "tokenized = DatasetDict({'train': train_tok, 'validation': val_tok})\n",
    "print(tokenized)\n",
    "\n",
    "## 4) Fine‑tuning\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference rapide\n",
    "\n",
    "prompts = [\n",
    "    \"Question : Explique l'exercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\",\n",
    "    \"Question : Décris l'exercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_len).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\n\\nGénérations :\")\n",
    "print(*tokenizer.batch_decode(outputs, skip_special_tokens=True), sep=\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation & visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perplexité de validation\n",
    "val_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"Perplexité validation : {perplexity:.2f}\")\n",
    "\n",
    "# Courbes de loss\n",
    "train_logs = [l for l in trainer.state.log_history if \"loss\" in l and l.get(\"epoch\") is not None]\n",
    "train_epochs = [l[\"epoch\"] for l in train_logs]\n",
    "train_losses = [l[\"loss\"] for l in train_logs]\n",
    "\n",
    "eval_logs = [l for l in trainer.state.log_history if \"eval_loss\" in l]\n",
    "eval_epochs = [l[\"epoch\"] for l in eval_logs]\n",
    "eval_losses = [l[\"eval_loss\"] for l in eval_logs]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, train_losses, label=\"Train loss\")\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m model = MT5ForConditionalGeneration.from_pretrained(model_name)\n\u001b[32m     93\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m training_args = Seq2SeqTrainingArguments(\n\u001b[32m     97\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./mt5-sportif-small\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     98\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m     remove_unused_columns=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    111\u001b[39m )\n\u001b[32m    114\u001b[39m data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3851\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3846\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3847\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3848\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3849\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3850\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Chatbot Coach Sportif en Français avec **mT5‑small** (FP16, batch ≤ 4)\n",
    "#\n",
    "# Ce notebook montre comment fine‑tuner **google/mt5‑small** pour générer des réponses de coaching sportif en français à partir du dataset **onurSakar/GYM‑Exercise**.\n",
    "# Paramètres pensés pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "#\n",
    "# **Plan :**\n",
    "# 1. Installation & imports  \n",
    "# 2. Préparation du dataset (split train/validation)  \n",
    "# 3. Tokenisation  \n",
    "# 4. Fine‑tuning  \n",
    "# 5. Inference & évaluation  \n",
    "# 6. Visualisation des métriques\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math, random\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Chargement et découpe des données\n",
    "\n",
    "# Le dataset ne contient qu'une seule colonne 'text' (instruction + réponse)\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "# Sous-échantillonnage : 600 exemples pour une démo rapide (500 train / 100 val)\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "# Split en train et validation\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "## 3) Pré‑traitement & tokenisation Pré‑traitement & tokenisation\n",
    "\n",
    "# On parse la colonne 'text' pour extraire question et réponse\n",
    "import re\n",
    "\n",
    "def split_instruction_response(example):\n",
    "    text = example['text']\n",
    "    # Séparer instruction et réponse\n",
    "    parts = text.split(\"[/INST]\")\n",
    "    if len(parts) != 2:\n",
    "        return {\"input_text\": \"\", \"target_text\": \"\"}\n",
    "    instr_part, ans_part = parts\n",
    "    # Extraire la question après la balise de fin du SYS\n",
    "    question = instr_part.split(\"<</SYS>>\")[-1].strip()\n",
    "    # Nettoyer la réponse (enlever balises)\n",
    "    answer = ans_part.replace(\"</s>\", \"\").strip()\n",
    "    return {\"input_text\": question, \"target_text\": answer}\n",
    "\n",
    "# Appliquer le split sur les datasets bruts\n",
    "split_train = datasets['train'].map(split_instruction_response)\n",
    "split_val   = datasets['validation'].map(split_instruction_response)\n",
    "\n",
    "# Tokenisation\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_len, max_target_len = 128, 64\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Tokenize inputs\n",
    "    enc = tokenizer(batch['input_text'], max_length=max_input_len,\n",
    "                    truncation=True, padding='max_length')\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch['target_text'], max_length=max_target_len,\n",
    "                           truncation=True, padding='max_length')\n",
    "    enc['labels'] = labels['input_ids']\n",
    "    return enc\n",
    "\n",
    "train_tok = split_train.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "val_tok   = split_val.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "train_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "tokenized = DatasetDict({'train': train_tok, 'validation': val_tok})\n",
    "print(tokenized)\n",
    "\n",
    "## 4) Fine‑tuning\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    do_eval=True,            # active l’évaluation\n",
    "    eval_steps=200,          # fréquence d’évaluation\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference rapide\n",
    "\n",
    "prompts = [\n",
    "    \"Question : Explique l'exercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\",\n",
    "    \"Question : Décris l'exercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_len).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\n\\nGénérations :\")\n",
    "print(*tokenizer.batch_decode(outputs, skip_special_tokens=True), sep=\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation & visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perplexité de validation\n",
    "val_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"Perplexité validation : {perplexity:.2f}\")\n",
    "\n",
    "# Courbes de loss\n",
    "train_logs = [l for l in trainer.state.log_history if \"loss\" in l and l.get(\"epoch\") is not None]\n",
    "train_epochs = [l[\"epoch\"] for l in train_logs]\n",
    "train_losses = [l[\"loss\"] for l in train_logs]\n",
    "\n",
    "eval_logs = [l for l in trainer.state.log_history if \"eval_loss\" in l]\n",
    "eval_epochs = [l[\"epoch\"] for l in eval_logs]\n",
    "eval_losses = [l[\"eval_loss\"] for l in eval_logs]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, train_losses, label=\"Train loss\")\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.mt5.tokenization_mt5.MT5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7819/4201867815.py:115: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "/home/maxime/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 124\u001b[39m\n\u001b[32m    113\u001b[39m data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m trainer = Seq2SeqTrainer(\n\u001b[32m    116\u001b[39m     model=model,\n\u001b[32m    117\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m     data_collator=data_collator,\n\u001b[32m    122\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# ## 5) Inference rapide\u001b[39;00m\n\u001b[32m    129\u001b[39m prompts = [\n\u001b[32m    130\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mQuestion : Explique l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    131\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mQuestion : Décris l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    132\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/trainer.py:2606\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2602\u001b[39m         grad_norm = _grad_norm\n\u001b[32m   2604\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2606\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2608\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2610\u001b[39m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/accelerate/optimizer.py:179\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    177\u001b[39m         \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.gradient_state.is_xla_gradients_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/optim/adam.py:757\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    755\u001b[39m     exp_avg_sq_sqrt = torch._foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     exp_avg_sq_sqrt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[32m    760\u001b[39m torch._foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Chatbot Coach Sportif en Français avec **mT5‑small** (FP16, batch ≤ 4)\n",
    "#\n",
    "# Ce notebook montre comment fine‑tuner **google/mt5‑small** pour générer des réponses de coaching sportif en français à partir du dataset **onurSakar/GYM‑Exercise**.\n",
    "# Paramètres pensés pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "#\n",
    "# **Plan :**\n",
    "# 1. Installation & imports  \n",
    "# 2. Préparation du dataset (split train/validation)  \n",
    "# 3. Tokenisation  \n",
    "# 4. Fine‑tuning  \n",
    "# 5. Inference & évaluation  \n",
    "# 6. Visualisation des métriques\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math, random\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Chargement et découpe des données\n",
    "\n",
    "# Le dataset ne contient qu'une seule colonne 'text' (instruction + réponse)\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "# Sous-échantillonnage : 600 exemples pour une démo rapide (500 train / 100 val)\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "# Split en train et validation\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "## 3) Pré‑traitement & tokenisation Pré‑traitement & tokenisation\n",
    "\n",
    "# On parse la colonne 'text' pour extraire question et réponse\n",
    "import re\n",
    "\n",
    "def split_instruction_response(example):\n",
    "    text = example['text']\n",
    "    # Séparer instruction et réponse\n",
    "    parts = text.split(\"[/INST]\")\n",
    "    if len(parts) != 2:\n",
    "        return {\"input_text\": \"\", \"target_text\": \"\"}\n",
    "    instr_part, ans_part = parts\n",
    "    # Extraire la question après la balise de fin du SYS\n",
    "    question = instr_part.split(\"<</SYS>>\")[-1].strip()\n",
    "    # Nettoyer la réponse (enlever balises)\n",
    "    answer = ans_part.replace(\"</s>\", \"\").strip()\n",
    "    return {\"input_text\": question, \"target_text\": answer}\n",
    "\n",
    "# Appliquer le split sur les datasets bruts\n",
    "split_train = datasets['train'].map(split_instruction_response)\n",
    "split_val   = datasets['validation'].map(split_instruction_response)\n",
    "\n",
    "# Tokenisation\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_len, max_target_len = 128, 64\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Tokenize inputs\n",
    "    enc = tokenizer(batch['input_text'], max_length=max_input_len,\n",
    "                    truncation=True, padding='max_length')\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch['target_text'], max_length=max_target_len,\n",
    "                           truncation=True, padding='max_length')\n",
    "    enc['labels'] = labels['input_ids']\n",
    "    return enc\n",
    "\n",
    "train_tok = split_train.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "val_tok   = split_val.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "train_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "tokenized = DatasetDict({'train': train_tok, 'validation': val_tok})\n",
    "print(tokenized)\n",
    "\n",
    "## 4) Fine‑tuning\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",  # dossier de checkpoint\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=False,  # Désactivé FP16 pour éviter l'underflow (loss à 0),\n",
    "    learning_rate=1e-4,  # Learning rate légèrement augmenté\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    do_eval=True,            # évaluation pendant l'entraînement\n",
    "    eval_steps=200,          # fréquence d'évaluation\n",
    "    logging_steps=50,        # fréquence du logging\n",
    "    save_steps=200,          # fréquence de sauvegarde\n",
    "    save_total_limit=2,      # nombre de checkpoints conservés\n",
    "    remove_unused_columns=False,  # garde les colonnes tokenisées\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference rapide\n",
    "\n",
    "prompts = [\n",
    "    \"Question : Explique l'exercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\",\n",
    "    \"Question : Décris l'exercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_len).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\n\\nGénérations :\")\n",
    "print(*tokenizer.batch_decode(outputs, skip_special_tokens=True), sep=\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation & visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perplexité de validation\n",
    "val_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"Perplexité validation : {perplexity:.2f}\")\n",
    "\n",
    "# Courbes de loss\n",
    "train_logs = [l for l in trainer.state.log_history if \"loss\" in l and l.get(\"epoch\") is not None]\n",
    "train_epochs = [l[\"epoch\"] for l in train_logs]\n",
    "train_losses = [l[\"loss\"] for l in train_logs]\n",
    "\n",
    "eval_logs = [l for l in trainer.state.log_history if \"eval_loss\" in l]\n",
    "eval_epochs = [l[\"epoch\"] for l in eval_logs]\n",
    "eval_losses = [l[\"eval_loss\"] for l in eval_logs]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, train_losses, label=\"Train loss\")\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n",
      "Colonnes disponibles : ['text']\n",
      "Nombre total d'exemples : 600\n",
      "5 premiers exemples :\n",
      "--- Exemple 1 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> High-Pulley Cable Curl - Gethin Variation [/INST]Also known as a crucifix curl, the overhead cable curl is a biceps-focused exercise performed between two cable stacks, using a pair of D-handles. The arms and elbows are held at shoulder height throughout the movement, and both hands curl in toward the ears. This position is designed to eliminate shoulder involvement and momentum, while targeting the biceps peak. This movement is generally done for moderate to high reps, such as 8-12 reps per set or more, as part of arm-focused training. </s> \n",
      "\n",
      "--- Exemple 2 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> How can I develop a consistent exercise routine and stay motivated to achieve my fitness goals? [/INST]1. Set realistic and achievable goals. Break your goals down into manageable and measurable results. This will help keep you focused and motivated.\n",
      "\n",
      "2. Find an enjoyable form of exercise. If you don't enjoy your workout routine, you won't stick to it for very long.\n",
      "\n",
      "3. Schedule your workouts. Put exercise on your calender and try to stick to it as best as you can.\n",
      "\n",
      "4. Keep track of your progress. This will keep you motivated and help you monitor your success.\n",
      "\n",
      "5. Reward yourself. This reinforces a positive association with exercise and can keep you motivated and positive </s> \n",
      "\n",
      "--- Exemple 3 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> What are some effective strategies for managing and reducing cravings for unhealthy foods? [/INST]1. Avoid tempting triggers. Keep unhealthy foods out of sight, out of reach, and off your mind.\n",
      "\n",
      "2. Change your eating environment. Try eating in different settings and remove distractions.\n",
      "\n",
      "3. Eat a balanced diet. Make sure you’re providing your body with the nutrients it needs with food like whole grains, fruits, vegetables, and protein.\n",
      "\n",
      "4. Find healthy alternatives. If you’re craving a certain food, look for a healthier version of it.\n",
      "\n",
      "5. Distract yourself. Find an activity like reading, writing, or listening to music that can help take </s> \n",
      "\n",
      "--- Exemple 4 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> King Maker Push-up [/INST]The push-up is a popular bodyweight exercise that is commonly used in military and tactical physical fitness tests. It’s a classic movement to build upper-body muscle and strength, emphasizing the chest, triceps, and shoulders, but also working the upper back and core. </s> \n",
      "\n",
      "--- Exemple 5 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Lower back SMR [/INST]Lower back self-myofascial release (SMR) is a self-administered soft-tissue treatment, usually using a foam roller, lacrosse ball, or other \"trigger point\" massage tool. By applying pressure strategically to the quadratus lumborum or spinal erector (erector spinae) muscles of the lower back, some people find they can cause this often painful and tight area to relax or \"release.\" Lower back SMR is often accompanied by SMR on the glutes or piriformis muscles, or by stretches that target the piriformis or hips. However, some people find that SMR on the lower back can aggravate existing pain or injury, so be cautious when performing it. </s> \n",
      "\n",
      "Longueur moyenne des textes : 504.1 caractères\n",
      "Exemple de parsing :\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_instruction_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Tester la fonction de split sur le premier exemple\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExemple de parsing :\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m parsed = \u001b[43msplit_instruction_response\u001b[49m(raw[\u001b[32m0\u001b[39m])\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuestion extraite :\u001b[39m\u001b[33m\"\u001b[39m, parsed[\u001b[33m'\u001b[39m\u001b[33minput_text\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRéponse extraite :\u001b[39m\u001b[33m\"\u001b[39m, parsed[\u001b[33m'\u001b[39m\u001b[33mtarget_text\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'split_instruction_response' is not defined"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Chatbot Coach Sportif en Français avec **mT5‑small** (FP16, batch ≤ 4)\n",
    "#\n",
    "# Ce notebook montre comment fine‑tuner **google/mt5‑small** pour générer des réponses de coaching sportif en français à partir du dataset **onurSakar/GYM‑Exercise**.\n",
    "# Paramètres pensés pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "#\n",
    "# **Plan :**\n",
    "# 1. Installation & imports  \n",
    "# 2. Préparation du dataset (split train/validation)  \n",
    "# 3. Tokenisation  \n",
    "# 4. Fine‑tuning  \n",
    "# 5. Inference & évaluation  \n",
    "# 6. Visualisation des métriques\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math, random\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Chargement et découpe des données\n",
    "\n",
    "# Le dataset ne contient qu'une seule colonne 'text' (instruction + réponse)\n",
    "raw = load_dataset(\"onurSakar/GYM-Exercise\")['train']\n",
    "# Sous-échantillonnage : 600 exemples pour une démo rapide (500 train / 100 val)\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "# Split en train et validation\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.1) Exploration du dataset brut\n",
    "# Afficher les colonnes et la taille\n",
    "print(\"Colonnes disponibles :\", raw.column_names)\n",
    "print(\"Nombre total d'exemples :\", len(raw))\n",
    "\n",
    "# Afficher 5 premiers exemples bruts\n",
    "print(\"5 premiers exemples :\")\n",
    "for i, ex in enumerate(raw.select(range(5))):\n",
    "    print(f\"--- Exemple {i+1} ---\")\n",
    "    print(ex['text'], \"\\n\")\n",
    "\n",
    "\n",
    "# Étudier la structure : longueur moyenne du texte\n",
    "lengths = [len(ex['text']) for ex in raw]\n",
    "print(f\"Longueur moyenne des textes : {sum(lengths)/len(lengths):.1f} caractères\")\n",
    "\n",
    "# Tester la fonction de split sur le premier exemple\n",
    "print(\"Exemple de parsing :\")\n",
    "parsed = split_instruction_response(raw[0])\n",
    "print(\"Question extraite :\", parsed['input_text'])\n",
    "print(\"Réponse extraite :\", parsed['target_text'])\n",
    "\n",
    "## 3) Pré‑traitement & tokenisation Pré‑traitement & tokenisation\n",
    "\n",
    "# On parse la colonne 'text' pour extraire question et réponse\n",
    "import re\n",
    "\n",
    "def split_instruction_response(example):\n",
    "    text = example['text']\n",
    "    # Séparer instruction et réponse\n",
    "    parts = text.split(\"[/INST]\")\n",
    "    if len(parts) != 2:\n",
    "        return {\"input_text\": \"\", \"target_text\": \"\"}\n",
    "    instr_part, ans_part = parts\n",
    "    # Extraire la question après la balise de fin du SYS\n",
    "    question = instr_part.split(\"<</SYS>>\")[-1].strip()\n",
    "    # Nettoyer la réponse (enlever balises)\n",
    "    answer = ans_part.replace(\"</s>\", \"\").strip()\n",
    "    return {\"input_text\": question, \"target_text\": answer}\n",
    "\n",
    "# Appliquer le split sur les datasets bruts\n",
    "split_train = datasets['train'].map(split_instruction_response)\n",
    "split_val   = datasets['validation'].map(split_instruction_response)\n",
    "\n",
    "# Tokenisation\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer  = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_len, max_target_len = 128, 64\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Tokenize inputs\n",
    "    enc = tokenizer(batch['input_text'], max_length=max_input_len,\n",
    "                    truncation=True, padding='max_length')\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch['target_text'], max_length=max_target_len,\n",
    "                           truncation=True, padding='max_length')\n",
    "    enc['labels'] = labels['input_ids']\n",
    "    return enc\n",
    "\n",
    "train_tok = split_train.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "val_tok   = split_val.map(preprocess, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "train_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "tokenized = DatasetDict({'train': train_tok, 'validation': val_tok})\n",
    "print(tokenized)\n",
    "\n",
    "## 4) Fine‑tuning\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",  # dossier de checkpoint\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=False,  # Désactivé FP16 pour éviter l'underflow (loss à 0),\n",
    "    learning_rate=1e-4,  # Learning rate légèrement augmenté\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    do_eval=True,            # évaluation pendant l'entraînement\n",
    "    eval_steps=200,          # fréquence d'évaluation\n",
    "    logging_steps=50,        # fréquence du logging\n",
    "    save_steps=200,          # fréquence de sauvegarde\n",
    "    save_total_limit=2,      # nombre de checkpoints conservés\n",
    "    remove_unused_columns=False,  # garde les colonnes tokenisées\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Inference rapide\n",
    "\n",
    "prompts = [\n",
    "    \"Question : Explique l'exercice Bench Press pour cibler pectoraux. Type : Strength, équipement : Barbell.\",\n",
    "    \"Question : Décris l'exercice Squat pour les quadriceps. Type : Strength, équipement : Bodyweight.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_len).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\n\\nGénérations :\")\n",
    "print(*tokenizer.batch_decode(outputs, skip_special_tokens=True), sep=\"\\n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Évaluation & visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perplexité de validation\n",
    "val_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(val_loss)\n",
    "print(f\"Perplexité validation : {perplexity:.2f}\")\n",
    "\n",
    "# Courbes de loss\n",
    "train_logs = [l for l in trainer.state.log_history if \"loss\" in l and l.get(\"epoch\") is not None]\n",
    "train_epochs = [l[\"epoch\"] for l in train_logs]\n",
    "train_losses = [l[\"loss\"] for l in train_logs]\n",
    "\n",
    "eval_logs = [l for l in trainer.state.log_history if \"eval_loss\" in l]\n",
    "eval_epochs = [l[\"epoch\"] for l in eval_logs]\n",
    "eval_losses = [l[\"eval_loss\"] for l in eval_logs]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, train_losses, label=\"Train loss\")\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1660\n",
      "    })\n",
      "})\n",
      "Colonnes du split 'train': ['text']\n",
      "Exemple brut du split 'train':   <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Is it possible to build muscle while losing weight? [/INST]Yes, it's possible but challenging. Focus on a slight calorie deficit, prioritize protein intake, and incorporate strength training. Accept that muscle gains may be slower during weight loss phases. </s>\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n",
      "--- Exemple 1 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> High-Pulley Cable Curl - Gethin Variation [/INST]Also known as a crucifix curl, the overhead cable curl is a biceps-focused exercise performed between two cable stacks, using a pair of D-handles. The arms and elbows are held at shoulder height throughout the movement, and both hands curl in toward the ears. This position is designed to eliminate shoulder involvement and momentum, while targeting the biceps peak. This movement is generally done for moderate to high reps, such as 8-12 reps per set or more, as part of arm-focused training. </s> \n",
      "\n",
      "--- Exemple 2 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> How can I develop a consistent exercise routine and stay motivated to achieve my fitness goals? [/INST]1. Set realistic and achievable goals. Break your goals down into manageable and measurable results. This will help keep you focused and motivated.\n",
      "\n",
      "2. Find an enjoyable form of exercise. If you don't enjoy your workout routine, you won't stick to it for very long.\n",
      "\n",
      "3. Schedule your workouts. Put exercise on your calender and try to stick to it as best as you can.\n",
      "\n",
      "4. Keep track of your progress. This will keep you motivated and help you monitor your success.\n",
      "\n",
      "5. Reward yourself. This reinforces a positive association with exercise and can keep you motivated and positive </s> \n",
      "\n",
      "--- Exemple 3 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> What are some effective strategies for managing and reducing cravings for unhealthy foods? [/INST]1. Avoid tempting triggers. Keep unhealthy foods out of sight, out of reach, and off your mind.\n",
      "\n",
      "2. Change your eating environment. Try eating in different settings and remove distractions.\n",
      "\n",
      "3. Eat a balanced diet. Make sure you’re providing your body with the nutrients it needs with food like whole grains, fruits, vegetables, and protein.\n",
      "\n",
      "4. Find healthy alternatives. If you’re craving a certain food, look for a healthier version of it.\n",
      "\n",
      "5. Distract yourself. Find an activity like reading, writing, or listening to music that can help take </s> \n",
      "\n",
      "--- Exemple 4 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> King Maker Push-up [/INST]The push-up is a popular bodyweight exercise that is commonly used in military and tactical physical fitness tests. It’s a classic movement to build upper-body muscle and strength, emphasizing the chest, triceps, and shoulders, but also working the upper back and core. </s> \n",
      "\n",
      "--- Exemple 5 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Lower back SMR [/INST]Lower back self-myofascial release (SMR) is a self-administered soft-tissue treatment, usually using a foam roller, lacrosse ball, or other \"trigger point\" massage tool. By applying pressure strategically to the quadratus lumborum or spinal erector (erector spinae) muscles of the lower back, some people find they can cause this often painful and tight area to relax or \"release.\" Lower back SMR is often accompanied by SMR on the glutes or piriformis muscles, or by stretches that target the piriformis or hips. However, some people find that SMR on the lower back can aggravate existing pain or injury, so be cautious when performing it. </s> \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 500/500 [00:00<00:00, 14360.81 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 10898.26 examples/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n",
      "Map:   0%|          | 0/500 [00:00<?, ? examples/s]/home/maxime/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 2893.12 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 2626.76 examples/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    105\u001b[39m model = MT5ForConditionalGeneration.from_pretrained(model_name)\n\u001b[32m    106\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m training_args = Seq2SeqTrainingArguments(\n\u001b[32m    110\u001b[39m     output_dir=\u001b[33m'\u001b[39m\u001b[33m./mt5-sportif-small\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    111\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m     remove_unused_columns=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3851\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3846\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3847\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3848\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3849\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3850\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Chatbot Coach Sportif en Français avec mT5-small (batch_size=4)\n",
    "#\n",
    "# Ce notebook fine‑tune **google/mt5-small** sur le dataset **onurSakar/GYM-Exercise**.\n",
    "# Configuré pour un GPU RTX 3060 Laptop (6 Go VRAM).\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "%pip install -q transformers datasets evaluate accelerate\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    ")\n",
    "import torch, math\n",
    "\n",
    "# %%\n",
    "# 1.1) Vérification du chargement du dataset\n",
    "# Charger tous les splits disponibles\n",
    "ds = load_dataset(\"onurSakar/GYM-Exercise\")\n",
    "print(ds)\n",
    "if 'train' in ds:\n",
    "    print(\"Colonnes du split 'train':\", ds['train'].column_names)\n",
    "    print(\"Exemple brut du split 'train':\", ds['train'][0]['text'])\n",
    "else:\n",
    "    print(\"Splits disponibles:\", ds.keys())\n",
    "\n",
    "# %%\n",
    "# 2) Préparation du dataset (split train/validation)\n",
    "raw = ds['train']\n",
    "# Sous-échantillonnage pour démo rapide\n",
    "raw = raw.shuffle(seed=42).select(range(600))\n",
    "# 500 train, 100 validation\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    'train': split['train'],\n",
    "    'validation': split['test'],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "# %% [markdown]\n",
    "# 2.1) Exploration rapide du dataset brut\n",
    "# Afficher 5 exemples de la colonne 'text'\n",
    "for i, ex in enumerate(raw.select(range(5)), 1):\n",
    "    print(f\"--- Exemple {i} ---\")\n",
    "    print(ex['text'], '\\n')\n",
    "\n",
    "# %%\n",
    "# 3) Pré‑traitement & tokenisation\n",
    "# Fonction pour séparer instruction et réponse\n",
    "def split_instruction_response(example):\n",
    "    text = example['text']\n",
    "    parts = text.split(\"[/INST]\")\n",
    "    if len(parts) != 2:\n",
    "        return {'input_text': '', 'target_text': ''}\n",
    "    instr, ans = parts\n",
    "    # Nettoyer balises système\n",
    "    if '<</SYS>>' in instr:\n",
    "        instr = instr.split('<</SYS>>')[-1]\n",
    "    question = instr.replace('[INST]', '').strip()\n",
    "    answer = ans.replace('</s>', '').strip()\n",
    "    return {'input_text': question, 'target_text': answer}\n",
    "\n",
    "# Appliquer le split\n",
    "datasets = datasets.map(split_instruction_response, batched=False)\n",
    "\n",
    "# Tokenizer\n",
    "model_name = 'google/mt5-small'\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
    "max_input_length = 128\n",
    "max_target_length = 64\n",
    "\n",
    "def preprocess_fn(examples):\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        examples['input_text'],\n",
    "        max_length=max_input_length,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples['target_text'],\n",
    "            max_length=max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# Map et format\n",
    "train_tok = datasets['train'].map(preprocess_fn, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "val_tok = datasets['validation'].map(preprocess_fn, batched=True, remove_columns=['text','input_text','target_text'])\n",
    "\n",
    "# Conversion en format PyTorch\n",
    "train_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "val_tok.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "# %% [markdown]\n",
    "# 4) Fine‑tuning\n",
    "\n",
    "# %%\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./mt5-sportif-small',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=False,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# %% [markdown]\n",
    "# 5) Inference rapide & évaluation\n",
    "\n",
    "# %%\n",
    "# Génération d'exemples\n",
    "prompts = [\n",
    "    \"Question: Explique l'exercice Bench Press pour cibler pectoraux.\",\n",
    "    \"Question: Décris l'exercice Squat pour les quadriceps.\",\n",
    "]\n",
    "inputs = tokenizer(prompts, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length).to(device)\n",
    "outputs = model.generate(**inputs, max_length=64, num_beams=4)\n",
    "print(\"\\nGénérations :\")\n",
    "for out in tokenizer.batch_decode(outputs, skip_special_tokens=True):\n",
    "    print(out)\n",
    "\n",
    "# %% [markdown]\n",
    "# 6) Évaluation & visualisation\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "logs = trainer.state.log_history\n",
    "train_logs = [x for x in logs if 'loss' in x and 'epoch' in x]\n",
    "eval_logs = [x for x in logs if 'eval_loss' in x]\n",
    "epochs = [x['epoch'] for x in train_logs]\n",
    "train_losses = [x['loss'] for x in train_logs]\n",
    "eval_losses = [x['eval_loss'] for x in eval_logs]\n",
    "\n",
    "plt.plot(epochs, train_losses, label='Train loss')\n",
    "plt.plot(epochs, eval_losses, label='Eval loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Courbe de loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1660\n",
      "    })\n",
      "})\n",
      "\n",
      "Colonnes du split 'train' : ['text']\n",
      "Nombre d'exemples : 1660\n",
      "\n",
      "5 premiers exemples :\n",
      "--- Exemple 1 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Is it possible to build muscle while losing weight? [/INST]Yes, it's possible but challenging. Focus on a slight calorie deficit, prioritize protein intake, and incorporate strength training. Accept that muscle gains may be slower during weight loss phases. </s> \n",
      "\n",
      "--- Exemple 2 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> What are some strategies for managing and reducing the impact of environmental stressors, such as pollution or noise? [/INST]1. Install noise-reducing features in homes and offices, such as double-glazed windows, insulation materials, and soundproofing panels. \n",
      "\n",
      "2. Plant and maintain vegetation such as trees, shrubs, and vines to reduce noise, provide ventilation, and prevent dust and air pollution. \n",
      "\n",
      "3. Implement regulations, such as zoning laws, to limit the location and type of pollutant-emitting businesses. \n",
      "\n",
      "4. Use green and clean technologies such as solar panels to reduce air pollutants emitted from energy production. \n",
      "\n",
      "5. Regulate and enforce the proper disposal of hazardous </s> \n",
      "\n",
      "--- Exemple 3 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> How can I create a healthy environment at home, such as reducing exposure to toxins and promoting clean air and water? [/INST]1. Ventilate your home frequently. Open windows and doors to circulate fresh air, and run an air purifier to ensure that the air in your home is as clean as possible.\n",
      "\n",
      "2. Use all-natural cleaners and other household products to reduce toxins and exposure to chemicals. Avoid using aerosols and other products that contain VOCs.\n",
      "\n",
      "3. Utilize natural building materials, such as stone, wood, hemp, and bamboo instead of synthetic materials like vinyl and plastic to reduce off-gassing of toxic chemicals.\n",
      "\n",
      "4. Replace polluting sources of energy like fossil fuels with renewable </s> \n",
      "\n",
      "--- Exemple 4 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Are there any specific supplements or vitamins that can support overall health and well-being? [/INST]The best approach to overall health and wellbeing is to consume a balanced diet of whole foods such as fruits, vegetables, lean proteins, nuts, and seeds, and to take a multivitamin, probiotic, omega-3 fatty acids, and vitamin D. Additionally, some people may benefit from taking specific supplements, such as B vitamins for energy; Vitamin C for immunity; Iron, folate, and Vitamin B12 to support red blood cell production; Magnesium to support muscle and nerve functioning; and CoQ10 to support heart health. Consult with your doctor before starting any supplement regimen. </s> \n",
      "\n",
      "--- Exemple 5 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Can you recommend a pre-workout meal for early morning workouts? [/INST]Opt for easily digestible carbs and a bit of protein. A banana with almond butter or a small oatmeal bowl are good choices. Stay hydrated and allow some time to digest before exercising. </s> \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Étude du dataset onurSakar/GYM-Exercise\n",
    "#\n",
    "# Ce notebook analyse le format et le contenu du dataset disponible sur Hugging Face.\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "%pip install -q datasets matplotlib\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %%\n",
    "# 2) Chargement du dataset\n",
    "# Afficher les splits et le split 'train'\n",
    "ds = load_dataset(\"onurSakar/GYM-Exercise\")\n",
    "print(ds)\n",
    "train = ds['train']\n",
    "print(\"\\nColonnes du split 'train' :\", train.column_names)\n",
    "print(\"Nombre d'exemples :\", len(train))\n",
    "\n",
    "# %%\n",
    "# 3) Exploration visuelle de quelques exemples\n",
    "print(\"\\n5 premiers exemples :\")\n",
    "for i, ex in enumerate(train.select(range(5)), 1):\n",
    "    print(f\"--- Exemple {i} ---\")\n",
    "    print(ex['text'], \"\\n\")\n",
    "\n",
    "# %%\n",
    "# 4) Distribution de la longueur des textes (en caractères)\n",
    "lengths = [len(t) for t in train['text']]\n",
    "plt.hist(lengths, bins=20)\n",
    "plt.xlabel(\"Longueur du texte (caractères)\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.title(\"Distribution de la longueur des textes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 1715.10 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1635.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 5) Préparation des données pour le fine-tuning\n",
    "from transformers import MT5Tokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "max_input_length, max_target_length = 128, 64\n",
    "\n",
    "def split_and_tokenize(example):\n",
    "    text = example[\"text\"]\n",
    "    # Séparer instruction et réponse\n",
    "    if \"[/INST]\" in text:\n",
    "        instr, resp = text.split(\"[/INST]\", 1)\n",
    "    else:\n",
    "        instr, resp = text, \"\"\n",
    "    # Nettoyage des balises\n",
    "    instr = instr.replace(\"<s>[INST] <<SYS>>\", \"\").replace(\"<</SYS>>\", \"\").strip()\n",
    "    resp = resp.replace(\"</s>\", \"\").strip()\n",
    "    # Préparer input et target\n",
    "    input_enc = tokenizer(instr, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "    target_enc = tokenizer(resp, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
    "    return {\n",
    "        \"input_ids\": input_enc[\"input_ids\"],\n",
    "        \"attention_mask\": input_enc[\"attention_mask\"],\n",
    "        \"labels\": target_enc[\"input_ids\"],\n",
    "    }\n",
    "\n",
    "# Appliquer sur train/validation\n",
    "split = train.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets_tok = DatasetDict({\n",
    "    \"train\": split[\"train\"].map(split_and_tokenize, batched=False, remove_columns=[\"text\"]),\n",
    "    \"validation\": split[\"test\"].map(split_and_tokenize, batched=False, remove_columns=[\"text\"]),\n",
    "})\n",
    "print(datasets_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m model = MT5ForConditionalGeneration.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mgoogle/mt5-small\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Arguments d'entraînement\u001b[39;00m\n\u001b[32m     12\u001b[39m training_args = Seq2SeqTrainingArguments(\n\u001b[32m     13\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./mt5-sportif-small\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     remove_unused_columns=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3851\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3846\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3847\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3848\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3849\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3850\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 490.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 379.81 MiB is free. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Of the allocated memory 5.13 GiB is allocated by PyTorch, and 141.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 6) Fine-tuning du modèle\n",
    "from transformers import MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "\n",
    "# Charger le modèle\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Arguments d'entraînement\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    fp16=False,  # désactivé pour la stabilité\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 7) Inférence : exemples de génération\n",
    "prompts = [\n",
    "    \"Explique l'exercice Bench Press pour cibler les pectoraux. Type: Strength, équipement: Barbell.\",\n",
    "    \"Décris l'exercice Squat pour les quadriceps. Type: Strength, équipement: Bodyweight.\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    # Préparation des entrées\n",
    "    input_enc = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    # Génération\n",
    "    gen_ids = model.generate(\n",
    "        input_enc.input_ids,\n",
    "        attention_mask=input_enc.attention_mask,\n",
    "        max_length=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    # Affichage\n",
    "    output = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "    print(f\"Prompt : {prompt}\n",
    "Réponse : {output}\n",
    "\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1660\n",
      "    })\n",
      "})\n",
      "Colonnes du split 'train': ['text']\n",
      "Nombre d'exemples : 1660\n",
      "--- Exemple 1 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Is it possible to build muscle while losing weight? [/INST]Yes, it's possible but challenging. Focus on a slight calorie deficit, prioritize protein intake, and incorporate strength training. Accept that muscle gains may be slower during weight loss phases. </s>\n",
      "\n",
      "--- Exemple 2 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> What are some strategies for managing and reducing the impact of environmental stressors, such as pollution or noise? [/INST]1. Install noise-reducing features in homes and offices, such as double-glazed windows, insulation materials, and soundproofing panels. \n",
      "\n",
      "2. Plant and maintain vegetation such as trees, shrubs, and vines to reduce noise, provide ventilation, and prevent dust and air pollution. \n",
      "\n",
      "3. Implement regulations, such as zoning laws, to limit the location and type of pollutant-emitting businesses. \n",
      "\n",
      "4. Use green and clean technologies such as solar panels to reduce air pollutants emitted from energy production. \n",
      "\n",
      "5. Regulate and enforce the proper disposal of hazardous </s>\n",
      "\n",
      "--- Exemple 3 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> How can I create a healthy environment at home, such as reducing exposure to toxins and promoting clean air and water? [/INST]1. Ventilate your home frequently. Open windows and doors to circulate fresh air, and run an air purifier to ensure that the air in your home is as clean as possible.\n",
      "\n",
      "2. Use all-natural cleaners and other household products to reduce toxins and exposure to chemicals. Avoid using aerosols and other products that contain VOCs.\n",
      "\n",
      "3. Utilize natural building materials, such as stone, wood, hemp, and bamboo instead of synthetic materials like vinyl and plastic to reduce off-gassing of toxic chemicals.\n",
      "\n",
      "4. Replace polluting sources of energy like fossil fuels with renewable </s>\n",
      "\n",
      "--- Exemple 4 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Are there any specific supplements or vitamins that can support overall health and well-being? [/INST]The best approach to overall health and wellbeing is to consume a balanced diet of whole foods such as fruits, vegetables, lean proteins, nuts, and seeds, and to take a multivitamin, probiotic, omega-3 fatty acids, and vitamin D. Additionally, some people may benefit from taking specific supplements, such as B vitamins for energy; Vitamin C for immunity; Iron, folate, and Vitamin B12 to support red blood cell production; Magnesium to support muscle and nerve functioning; and CoQ10 to support heart health. Consult with your doctor before starting any supplement regimen. </s>\n",
      "\n",
      "--- Exemple 5 ---\n",
      "  <s>[INST] <<SYS>> Below is an instruction that describes a task. Write a response that appropriately completes the request <</SYS>> Can you recommend a pre-workout meal for early morning workouts? [/INST]Opt for easily digestible carbs and a bit of protein. A banana with almond butter or a small oatmeal bowl are good choices. Stay hydrated and allow some time to digest before exercising. </s>\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 500\n",
      "}) Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 61.81 MiB is free. Including non-PyTorch memory, this process has 5.72 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 115.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m     90\u001b[39m model = MT5ForConditionalGeneration.from_pretrained(\n\u001b[32m     91\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgoogle/mt5-small\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m     torch_dtype=torch.float16,\n\u001b[32m     93\u001b[39m     device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m )\n\u001b[32m     95\u001b[39m trainer_args = Seq2SeqTrainingArguments(\n\u001b[32m     96\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./mt5-sportif-small-fp16\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m     remove_unused_columns=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    111\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m trainer = \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_tok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_tok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m trainer.train()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# 7) Inférence : exemples de génération\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:72\u001b[39m, in \u001b[36mSeq2SeqTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mprocessing_class\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m5.0.0\u001b[39m\u001b[33m\"\u001b[39m, raise_if_both_names=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m     preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     71\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompute_loss_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_loss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.generation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/trainer.py:622\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    619\u001b[39m     \u001b[38;5;28mself\u001b[39m.place_model_on_device\n\u001b[32m    620\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mquantization_method\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == QuantizationMethod.BITS_AND_BYTES\n\u001b[32m    621\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_model_parallel:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/trainer.py:905\u001b[39m, in \u001b[36mTrainer._move_model_to_device\u001b[39m\u001b[34m(self, model, device)\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.parallel_mode == ParallelMode.TPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mtie_weights\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3851\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3846\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3847\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3848\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3849\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3850\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/coach_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 61.81 MiB is free. Including non-PyTorch memory, this process has 5.72 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 115.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Chatbot Coach Sportif en Français avec mT5-small (batch_size=4, 8-bit)\n",
    "#\n",
    "# Ce notebook présente le fine-tuning de **google/mt5-small** sur le dataset **onurSakar/GYM-Exercise**.\n",
    "# Configuré pour un GPU RTX 3060 Laptop (6 Go VRAM) avec quantification 8-bits et offload automatique.\n",
    "\n",
    "# %%\n",
    "# 1) Installation et imports\n",
    "%pip install -q transformers datasets evaluate accelerate bitsandbytes\n",
    "%pip install -q -U bitsandbytes accelerate transformers datasets evaluate\n",
    "\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    MT5Tokenizer,\n",
    "    MT5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# %%\n",
    "# 2) Chargement et exploration du dataset\n",
    "# Charger le split 'train'\n",
    "ds_full = load_dataset(\"onurSakar/GYM-Exercise\")\n",
    "print(ds_full)\n",
    "train_full = ds_full['train']\n",
    "print(\"Colonnes du split 'train':\", train_full.column_names)\n",
    "print(\"Nombre d'exemples :\", len(train_full))\n",
    "# Afficher 5 exemples bruts\n",
    "for i, ex in enumerate(train_full.select(range(5))):\n",
    "    print(f\"--- Exemple {i+1} ---\\n{ex['text']}\\n\")\n",
    "\n",
    "# %%\n",
    "# 3) Sous-échantillonnage et découpe train/validation\n",
    "raw = train_full.shuffle(seed=42).select(range(600))\n",
    "split = raw.train_test_split(train_size=500, test_size=100, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "})\n",
    "print(datasets)\n",
    "\n",
    "# %%\n",
    "# 4) Distribution de la longueur des textes (en caractères)\n",
    "import matplotlib.pyplot as plt\n",
    "lengths = [len(t) for t in raw['text']]\n",
    "plt.hist(lengths, bins=20)\n",
    "plt.xlabel(\"Longueur du texte (caractères)\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.title(\"Distribution de la longueur des textes\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# 5) Préparation des données pour le fine-tuning\n",
    "# Tokenizer\n",
    "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "max_input_length, max_target_length = 128, 64\n",
    "\n",
    "def split_and_tokenize(example):\n",
    "    text = example[\"text\"]\n",
    "    if \"[/INST]\" in text:\n",
    "        instr, resp = text.split(\"[/INST]\", 1)\n",
    "    else:\n",
    "        instr, resp = text, \"\"\n",
    "    instr = instr.replace(\"<s>[INST] <<SYS>>\", \"\").replace(\"<</SYS>>\", \"\").strip()\n",
    "    resp = resp.replace(\"</s>\", \"\").strip()\n",
    "    input_enc = tokenizer(instr, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "    target_enc = tokenizer(resp, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
    "    return {\n",
    "        \"input_ids\": input_enc[\"input_ids\"],\n",
    "        \"attention_mask\": input_enc[\"attention_mask\"],\n",
    "        \"labels\": target_enc[\"input_ids\"],\n",
    "    }\n",
    "\n",
    "# Appliquer mapping\n",
    "train_tok = datasets['train'].map(split_and_tokenize, batched=False, remove_columns=[\"text\"])\n",
    "val_tok   = datasets['validation'].map(split_and_tokenize, batched=False, remove_columns=[\"text\"])\n",
    "# Format PyTorch\n",
    "train_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "val_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "print(train_tok, val_tok)\n",
    "\n",
    "# %%\n",
    "# 6) Fine‑tuning du modèle en 8-bits\n",
    "# Charger le modèle en 8-bit avec offload\n",
    "# 6) Fine-tuning du modèle en float16 avec offload automatique\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/mt5-small\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "trainer_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-sportif-small-fp16\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,      # batch réduit\n",
    "    per_device_eval_batch_size=2,\n",
    "    fp16=True,                          # précision mixte\n",
    "    gradient_checkpointing=True,        # économise de la VRAM\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# %%\n",
    "# 7) Inférence : exemples de génération\n",
    "prompts = [\n",
    "    \"Explique l'exercice Bench Press pour cibler les pectoraux. Type: Strength, équipement: Barbell.\",\n",
    "    \"Décris l'exercice Squat pour les quadriceps. Type: Strength, équipement: Bodyweight.\",\n",
    "]\n",
    "for prompt in prompts:\n",
    "    input_enc = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    gen_ids = model.generate(\n",
    "        input_enc.input_ids,\n",
    "        attention_mask=input_enc.attention_mask,\n",
    "        max_length=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    output = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "    print(f\"Prompt : {prompt}\\nRéponse : {output}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n🚨 Forgot to compile the bitsandbytes library? 🚨\n1. You're not using the package but checked-out the source code\n2. You MUST compile from source\n\nAttempted to use bitsandbytes native library functionality but it's not available.\n\nThis typically happens when:\n1. bitsandbytes doesn't ship with a pre-compiled binary for your CUDA version\n2. The library wasn't compiled properly during installation from source\n\nTo make bitsandbytes work, the compiled library version MUST exactly match the linked CUDA version.\nIf your CUDA version doesn't have a pre-compiled binary, you MUST compile from source.\n\nYou have two options:\n1. COMPILE FROM SOURCE (required if no binary exists):\n   https://huggingface.co/docs/bitsandbytes/main/en/installation#cuda-compile\n2. Use BNB_CUDA_VERSION to specify a DIFFERENT CUDA version from the detected one, which is installed on your machine and matching an available pre-compiled version listed above\n\nOriginal error: Configured CUDA binary not found at /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n\n🔍 Run this command for detailed diagnostics:\npython -m bitsandbytes\n\nIf you've tried everything and still have issues:\n1. Include ALL version info (operating system, bitsandbytes, pytorch, cuda, python)\n2. Describe what you've tried in detail\n3. Open an issue with this information:\n   https://github.com/bitsandbytes-foundation/bitsandbytes/issues\n\nNative code method attempted to call: lib.cquantize_blockwise_fp16_nf4()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 3) Quantisation 4-bits + ajout des adaptateurs LoRA\u001b[39;00m\n\u001b[32m     39\u001b[39m bnb_cfg = BitsAndBytesConfig(\n\u001b[32m     40\u001b[39m     load_in_4bit            = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     41\u001b[39m     bnb_4bit_quant_type     = \u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     bnb_4bit_use_double_quant=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     43\u001b[39m     bnb_4bit_compute_dtype  = torch.float16,\n\u001b[32m     44\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m base_model = \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbnb_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# garde l'offload\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m lora_cfg = LoraConfig(\n\u001b[32m     53\u001b[39m     r                = \u001b[32m8\u001b[39m,\n\u001b[32m     54\u001b[39m     lora_alpha       = \u001b[32m32\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     target_modules   = [\u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mo\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# proj. de T5\u001b[39;00m\n\u001b[32m     59\u001b[39m )\n\u001b[32m     61\u001b[39m model = get_peft_model(base_model, lora_cfg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4574\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4565\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4567\u001b[39m     (\n\u001b[32m   4568\u001b[39m         model,\n\u001b[32m   4569\u001b[39m         missing_keys,\n\u001b[32m   4570\u001b[39m         unexpected_keys,\n\u001b[32m   4571\u001b[39m         mismatched_keys,\n\u001b[32m   4572\u001b[39m         offload_index,\n\u001b[32m   4573\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4580\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4583\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4592\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4593\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:5031\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5029\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m   5030\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m-> \u001b[39m\u001b[32m5031\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5043\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5045\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[32m   5050\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:846\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    843\u001b[39m     _load_parameter_into_model(model, param_name, param.to(param_device))\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m846\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    849\u001b[39m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[32m    850\u001b[39m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[32m    851\u001b[39m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[32m    852\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:243\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.create_quantized_param\u001b[39m\u001b[34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[39m\n\u001b[32m    240\u001b[39m         new_value = new_value.T\n\u001b[32m    242\u001b[39m     kwargs = old_value.\u001b[34m__dict__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     new_value = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m module._parameters[tensor_name] = new_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:337\u001b[39m, in \u001b[36mParams4bit.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device.type != \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bnb_quantized:\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:296\u001b[39m, in \u001b[36mParams4bit._quantize\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[32m    295\u001b[39m     w = \u001b[38;5;28mself\u001b[39m.data.contiguous().to(device)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     w_4bit, quant_state = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = w_4bit\n\u001b[32m    304\u001b[39m     \u001b[38;5;28mself\u001b[39m.quant_state = quant_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/functional.py:923\u001b[39m, in \u001b[36mquantize_4bit\u001b[39m\u001b[34m(A, absmax, out, blocksize, compress_statistics, quant_type, quant_storage)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Quantize tensor A in blocks of 4-bit values.\u001b[39;00m\n\u001b[32m    899\u001b[39m \n\u001b[32m    900\u001b[39m \u001b[33;03mQuantizes tensor A by dividing it into blocks which are independently quantized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    919\u001b[39m \u001b[33;03m    - [`QuantState`]: The state object used to undo the quantization.\u001b[39;00m\n\u001b[32m    920\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    921\u001b[39m input_shape = A.shape\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m _out, _absmax = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitsandbytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m code = get_4bit_type(quant_type, device=A.device)\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compress_statistics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/torch/_ops.py:756\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/torch/_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/torch/library.py:719\u001b[39m, in \u001b[36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_no_dynamo\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/backends/cuda/ops.py:328\u001b[39m, in \u001b[36m_\u001b[39m\u001b[34m(A, blocksize, quant_type, quant_storage)\u001b[39m\n\u001b[32m    326\u001b[39m         lib.cquantize_blockwise_fp16_fp4(*args)\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m         \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcquantize_blockwise_fp16_nf4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m A.dtype == torch.float32:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m quant_type == \u001b[33m\"\u001b[39m\u001b[33mfp4\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:251\u001b[39m, in \u001b[36mErrorHandlerMockBNBNativeLibrary.__getattr__.<locals>.throw_on_call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mthrow_on_call\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.formatted_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mNative code method attempted to call: lib.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: \n🚨 Forgot to compile the bitsandbytes library? 🚨\n1. You're not using the package but checked-out the source code\n2. You MUST compile from source\n\nAttempted to use bitsandbytes native library functionality but it's not available.\n\nThis typically happens when:\n1. bitsandbytes doesn't ship with a pre-compiled binary for your CUDA version\n2. The library wasn't compiled properly during installation from source\n\nTo make bitsandbytes work, the compiled library version MUST exactly match the linked CUDA version.\nIf your CUDA version doesn't have a pre-compiled binary, you MUST compile from source.\n\nYou have two options:\n1. COMPILE FROM SOURCE (required if no binary exists):\n   https://huggingface.co/docs/bitsandbytes/main/en/installation#cuda-compile\n2. Use BNB_CUDA_VERSION to specify a DIFFERENT CUDA version from the detected one, which is installed on your machine and matching an available pre-compiled version listed above\n\nOriginal error: Configured CUDA binary not found at /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n\n🔍 Run this command for detailed diagnostics:\npython -m bitsandbytes\n\nIf you've tried everything and still have issues:\n1. Include ALL version info (operating system, bitsandbytes, pytorch, cuda, python)\n2. Describe what you've tried in detail\n3. Open an issue with this information:\n   https://github.com/bitsandbytes-foundation/bitsandbytes/issues\n\nNative code method attempted to call: lib.cquantize_blockwise_fp16_nf4()"
     ]
    }
   ],
   "source": [
    "# 1) Dépendances\n",
    "%pip install -q -U transformers datasets accelerate bitsandbytes peft sentencepiece\n",
    "\n",
    "from datasets         import load_dataset\n",
    "from transformers     import (AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "                               DataCollatorForSeq2Seq, Seq2SeqTrainer,\n",
    "                               Seq2SeqTrainingArguments, BitsAndBytesConfig)\n",
    "from peft             import LoraConfig, get_peft_model, TaskType\n",
    "import torch, random\n",
    "\n",
    "MODEL_NAME = \"google/mt5-small\"          # reste multilangue\n",
    "MAX_IN, MAX_OUT = 128, 64\n",
    "\n",
    "# 2) Dataset (identique à votre notebook, mais réduit pour l'exemple)\n",
    "raw_ds  = load_dataset(\"onurSakar/GYM-Exercise\", split=\"train\")\n",
    "raw_ds  = raw_ds.shuffle(seed=42).select(range(600))\n",
    "splits  = raw_ds.train_test_split(train_size=500, seed=42)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(ex):\n",
    "    txt = ex[\"text\"]\n",
    "    if \"[/INST]\" in txt:\n",
    "        instr, resp = txt.split(\"[/INST]\", 1)\n",
    "    else:\n",
    "        instr, resp = txt, \"\"\n",
    "    instr = instr.replace(\"<s>[INST] <<SYS>>\", \"\").replace(\"<</SYS>>\", \"\").strip()\n",
    "    resp  = resp.replace(\"</s>\", \"\").strip()\n",
    "    model_in  = tokenizer(instr, max_length=MAX_IN,  truncation=True, padding=\"max_length\")\n",
    "    model_out = tokenizer(resp,  max_length=MAX_OUT, truncation=True, padding=\"max_length\")\n",
    "    model_in[\"labels\"] = model_out[\"input_ids\"]\n",
    "    return model_in\n",
    "\n",
    "train_ds = splits[\"train\"].map(preprocess, remove_columns=[\"text\"])\n",
    "val_ds   = splits[\"test\"] .map(preprocess, remove_columns=[\"text\"])\n",
    "train_ds.set_format(type=\"torch\")\n",
    "val_ds.set_format(type=\"torch\")\n",
    "\n",
    "# 3) Quantisation 4-bits + ajout des adaptateurs LoRA\n",
    "bnb_cfg = BitsAndBytesConfig(\n",
    "    load_in_4bit            = True,\n",
    "    bnb_4bit_quant_type     = \"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype  = torch.float16,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config = bnb_cfg,\n",
    "    device_map          = \"auto\"        # garde l'offload\n",
    ")\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r                = 8,\n",
    "    lora_alpha       = 32,\n",
    "    lora_dropout     = 0.05,\n",
    "    bias             = \"none\",\n",
    "    task_type        = TaskType.SEQ_2_SEQ_LM,\n",
    "    target_modules   = [\"q\", \"v\", \"k\", \"o\"]  # proj. de T5\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "model.print_trainable_parameters()  # ≈ 5 M params seulement\n",
    "\n",
    "# 4) Entraînement\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir                   = \"./mt5-gym-lora\",\n",
    "    num_train_epochs             = 3,\n",
    "    per_device_train_batch_size  = 1,\n",
    "    gradient_accumulation_steps  = 16,   # => batch effectif de 16\n",
    "    learning_rate                = 2e-4,\n",
    "    fp16                         = True,\n",
    "    logging_steps                = 10,\n",
    "    save_steps                   = 200,\n",
    "    optim                        = \"paged_adamw_32bit\",  # mémoire CPU\n",
    "    report_to                    = \"none\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model            = model,\n",
    "    args             = training_args,\n",
    "    train_dataset    = train_ds,\n",
    "    eval_dataset     = val_ds,\n",
    "    data_collator    = data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python - << EOF\n",
    "import bitsandbytes as bnb\n",
    "print(\"GPU support disponible :\", bnb.cuda.is_available())\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
