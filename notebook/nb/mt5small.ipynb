{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouvelle version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/maxime/DataDevIA/chatbotcoach_project/notebook\n",
      "Lecture : ../data/stackexchange/Posts.xml\n",
      "→ 4761 paires Q/R chargées\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8ee5e435-0e6b-4df2-8c54-e658df4e0d65",
       "rows": [
        [
         "0",
         "What's the difference between Whey Isolate and Whey Concentrate in shakes?",
         "<p>What's the difference? I'm looking at shake options and some contain whey isolate, some contain whey concentrate and some both.</p>\n",
         "<protein><nutrition>",
         "<p>The main difference is in the \"purity\", how much lactose and fat is left with the protein after filtering. Whey isolate usually contains around 90% protein and whey concentrate is more like 70-85%.</p>\n\n<p>If you have trouble digesting the lactose or are trying to minimize carbohydrate content, then whey isolate would be a good choice. Otherwise, it probably doesn't matter; just pick the concentrate since it's cheaper in terms of protein grams/dollar. </p>\n"
        ],
        [
         "1",
         "Breakfast before or after jogging?",
         "<p>Provided that I'm not hungry, should I eat breakfast before or after a 30-minutes morning jog?</p>\n\n<p><strong>Update</strong>: There are many answers detailing opinions -- thanks! If someone could supply evidence supporting their view, I'd be even happier.</p>\n",
         "<nutrition><food><jogging>",
         "<p>I'd say this depends on your fitness, the intensity of the workout and perhaps how much you've eaten the night before.</p>\n\n<p>Assuming jogging means a running speed of about ~10 km/h or ~6 mph, I expect you don't use that much energy that you can't cope with without jogging. More importantly, low intensity workouts mainly burn through fat and anything you would eat either isn't absorbed yet or only serves you energy for a couple of minutes, which won't help you during 'longer' workouts.</p>\n\n<p>Off course, if you start to feel faint at the end of the workout, you could take some glucose with you, just to recharge when you need it.</p>\n\n<p>So my advise: <strong>go running and enjoy your breakfast after the workout!</strong></p>\n\n<hr>\n\n<p>Resources:</p>\n\n<ol>\n<li><a href=\"http://www.usatoday.com/news/health/2010-06-04-eating-exercise_N.htm\">Skip breakfast before exercise to burn more fat, studies say</a> </li>\n<li><a href=\"http://well.blogs.nytimes.com/2010/12/15/phys-ed-the-benefits-of-exercising-before-breakfast/\">The Benefits of Exercising Before Breakfast</a></li>\n</ol>\n"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the difference between Whey Isolate and...</td>\n",
       "      <td>&lt;p&gt;What's the difference? I'm looking at shake...</td>\n",
       "      <td>&lt;protein&gt;&lt;nutrition&gt;</td>\n",
       "      <td>&lt;p&gt;The main difference is in the \"purity\", how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breakfast before or after jogging?</td>\n",
       "      <td>&lt;p&gt;Provided that I'm not hungry, should I eat ...</td>\n",
       "      <td>&lt;nutrition&gt;&lt;food&gt;&lt;jogging&gt;</td>\n",
       "      <td>&lt;p&gt;I'd say this depends on your fitness, the i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What's the difference between Whey Isolate and...   \n",
       "1                 Breakfast before or after jogging?   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>What's the difference? I'm looking at shake...   \n",
       "1  <p>Provided that I'm not hungry, should I eat ...   \n",
       "\n",
       "                         tags  \\\n",
       "0        <protein><nutrition>   \n",
       "1  <nutrition><food><jogging>   \n",
       "\n",
       "                                              answer  \n",
       "0  <p>The main difference is in the \"purity\", how...  \n",
       "1  <p>I'd say this depends on your fitness, the i...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "# Deux options : depuis la racine ou depuis notebook/\n",
    "candidates = [\n",
    "    Path(\"data/stackexchange/Posts.xml\"),\n",
    "    Path(\"../data/stackexchange/Posts.xml\"),\n",
    "]\n",
    "xml_path = next((p for p in candidates if p.exists()), None)\n",
    "if xml_path is None:\n",
    "    raise FileNotFoundError(\"Posts.xml introuvable (chemins testés : {})\"\n",
    "                            .format([str(p) for p in candidates]))\n",
    "print(\"Lecture :\", xml_path)\n",
    "\n",
    "tree = ET.parse(xml_path)\n",
    "\n",
    "# — Dictionnaire réponses\n",
    "answers_map = {\n",
    "    int(r.attrib[\"Id\"]): r.attrib[\"Body\"]\n",
    "    for r in tree.iter(\"row\") if r.attrib.get(\"PostTypeId\") == \"2\"\n",
    "}\n",
    "\n",
    "# — Questions + réponse acceptée\n",
    "questions = []\n",
    "for q in tree.iter(\"row\"):\n",
    "    if q.attrib.get(\"PostTypeId\") == \"1\" and \"AcceptedAnswerId\" in q.attrib:\n",
    "        aid = int(q.attrib[\"AcceptedAnswerId\"])\n",
    "        if aid in answers_map:\n",
    "            questions.append({\n",
    "                \"title\":  q.attrib.get(\"Title\", \"\"),\n",
    "                \"body\":   q.attrib.get(\"Body\", \"\"),\n",
    "                \"tags\":   q.attrib.get(\"Tags\", \"\"),\n",
    "                \"answer\": answers_map[aid]\n",
    "            })\n",
    "\n",
    "posts_df = pd.DataFrame(questions)\n",
    "print(f\"→ {len(posts_df)} paires Q/R chargées\")\n",
    "posts_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "q_en",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "a_en",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4fb1a413-831e-429a-b1c0-d02f10b559e2",
       "rows": [
        [
         "0",
         "What's the difference between Whey Isolate and Whey Concentrate in shakes? What's the difference? I'm looking at shake options and some contain whey isolate, some contain whey concentrate and some both.",
         "The main difference is in the \"purity\", how much lactose and fat is left with the protein after filtering. Whey isolate usually contains around 90% protein and whey concentrate is more like 70-85%. If you have trouble digesting the lactose or are trying to minimize carbohydrate content, then whey isolate would be a good choice. Otherwise, it probably doesn't matter; just pick the concentrate since it's cheaper in terms of protein grams/dollar."
        ],
        [
         "1",
         "Breakfast before or after jogging? Provided that I'm not hungry, should I eat breakfast before or after a 30-minutes morning jog? Update : There are many answers detailing opinions -- thanks! If someone could supply evidence supporting their view, I'd be even happier.",
         "I'd say this depends on your fitness, the intensity of the workout and perhaps how much you've eaten the night before. Assuming jogging means a running speed of about ~10 km/h or ~6 mph, I expect you don't use that much energy that you can't cope with without jogging. More importantly, low intensity workouts mainly burn through fat and anything you would eat either isn't absorbed yet or only serves you energy for a couple of minutes, which won't help you during 'longer' workouts. Off course, if you start to feel faint at the end of the workout, you could take some glucose with you, just to recharge when you need it. So my advise: go running and enjoy your breakfast after the workout! Resources: Skip breakfast before exercise to burn more fat, studies say The Benefits of Exercising Before Breakfast"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_en</th>\n",
       "      <th>a_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the difference between Whey Isolate and...</td>\n",
       "      <td>The main difference is in the \"purity\", how mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breakfast before or after jogging? Provided th...</td>\n",
       "      <td>I'd say this depends on your fitness, the inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                q_en  \\\n",
       "0  What's the difference between Whey Isolate and...   \n",
       "1  Breakfast before or after jogging? Provided th...   \n",
       "\n",
       "                                                a_en  \n",
       "0  The main difference is in the \"purity\", how mu...  \n",
       "1  I'd say this depends on your fitness, the inte...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    raw = BeautifulSoup(text, \"lxml\").get_text(\" \")\n",
    "    return re.sub(r\"\\s+\", \" \", html.unescape(raw)).strip()\n",
    "\n",
    "posts_df[\"q_en\"] = posts_df[\"title\"].apply(strip_html) + \" \" + posts_df[\"body\"].apply(strip_html)\n",
    "posts_df[\"a_en\"] = posts_df[\"answer\"].apply(strip_html)\n",
    "posts_df = posts_df[[\"q_en\", \"a_en\"]]\n",
    "posts_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape de traduction, demande plusieurs heures de calculs sur GPU, bonus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Map: 100%|██████████| 4761/4761 [08:24<00:00,  9.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tok_mt  = AutoTokenizer.from_pretrained(model_name)\n",
    "mod_mt  = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\", dtype=torch.float16)\n",
    "\n",
    "def translate_list(texts, max_tokens=128):\n",
    "    # Tronque avant tokenisation pour éviter >512\n",
    "    encoded = tok_mt(\n",
    "        texts, padding=True, truncation=True,\n",
    "        max_length=max_tokens, return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        out = mod_mt.generate(\n",
    "            **encoded,\n",
    "            max_length=max_tokens,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    return tok_mt.batch_decode(out, skip_special_tokens=True)\n",
    "\n",
    "def translate_batch(batch):\n",
    "    batch[\"q_fr\"] = translate_list(batch[\"q_en\"])\n",
    "    batch[\"a_fr\"] = translate_list(batch[\"a_en\"])\n",
    "    return batch\n",
    "\n",
    "dataset_raw = Dataset.from_pandas(posts_df)\n",
    "dataset_tr  = dataset_raw.map(\n",
    "    translate_batch,\n",
    "    batched=True,\n",
    "    batch_size=64,         # GPU → batch 64 passe sur 6 Go en FP16\n",
    "    remove_columns=[\"q_en\", \"a_en\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sauvegarde du dataset traduit en francais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 4761/4761 [00:00<00:00, 537236.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 1) Sauvegarde du dataset HF sur disque\n",
    "dataset_tr.save_to_disk(\"data/stackexchange/translated_dataset_fr\")\n",
    "\n",
    "# 2) Plus tard, pour recharger sans retraduire :\n",
    "from datasets import load_from_disk\n",
    "dataset_tr = load_from_disk(\"data/stackexchange/translated_dataset_fr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855 train | 429 val | 477 test\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# 1) Charger le dataset traduit\n",
    "dataset_tr = load_from_disk(\"data/stackexchange/translated_dataset_fr\")\n",
    "\n",
    "# 2) Split train / val / test sur dataset_tr\n",
    "split1  = dataset_tr.train_test_split(test_size=0.1, seed=42)\n",
    "test_ds = split1[\"test\"]\n",
    "tmp     = split1[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "train_ds, val_ds = tmp[\"train\"], tmp[\"test\"]\n",
    "\n",
    "# 3) Vérification\n",
    "print(len(train_ds), \"train |\", len(val_ds), \"val |\", len(test_ds), \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes du train_ds : ['q_fr', 'a_fr']\n",
      "Exemple : {'q_fr': \"J'aimerais faire du ski de fond cet hiver pour mon prochain Marathon. Ma question est de savoir si je peux skier pendant un certain nombre d'heures et cela aura un impact sur mon entraînement normal? Mon dernier marathon j'ai couru 50-60 miles par semaine mais j'aimerais ajouter d'autres types d'exercices à mon prochain cycle d'entraînement. Ai-je besoin de plus d'une journée de repos complète ou puis-je courir une longue journée puis skier pendant un certain nombre d'heures?\", 'a_fr': \"Oui, le ski aura un impact sur votre entraînement normal (et vice versa). Si vous allez skier pendant un certain nombre d'heures, vous ferez des choses biomécaniques différentes, mais vous insisterez sur les mêmes systèmes. Ne faites pas deux longs efforts en deux jours. Fait amusant: élite 5K et 10K coureur Ben True était un skieur nordique avant de se concentrer entièrement sur la course: http://www.runnersworld.com/tag/ben-true\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes du train_ds :\", train_ds.column_names)\n",
    "print(\"Exemple :\", train_ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.mt5.tokenization_mt5.MT5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant map, colonnes de train_ds : ['q_fr', 'a_fr']\n",
      "Après map, colonnes : ['input_ids', 'attention_mask', 'labels']\n",
      "Exemple de clés : dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "# ─── Cellule 4 (version traduite FR) – Tokenisation & préparation des features ───\n",
    "\n",
    "from transformers import MT5Tokenizer\n",
    "\n",
    "# 1) Charger le tokenizer mT5 (slow) sans erreur protobuf\n",
    "tok = MT5Tokenizer.from_pretrained(\"google/mt5-small\", model_max_length=512)\n",
    "\n",
    "# 2) Vérifier que train_ds contient bien les colonnes FR\n",
    "print(\"Avant map, colonnes de train_ds :\", train_ds.column_names)\n",
    "# → vous devriez voir ['q_fr','a_fr']\n",
    "\n",
    "# 3) Utiliser les colonnes FR pour l'entraînement\n",
    "input_col, target_col = \"q_fr\", \"a_fr\"\n",
    "MAX_IN, MAX_OUT       = 192, 128\n",
    "\n",
    "def preprocess(batch):\n",
    "    # On explicite le format question→réponse\n",
    "    inputs  = [\"question: \" + q for q in batch[input_col]]\n",
    "    targets = [\"answer:   \" + a for a in batch[target_col]]\n",
    "\n",
    "    model_in  = tok(\n",
    "        inputs,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_IN\n",
    "    )\n",
    "    model_out = tok(\n",
    "        targets,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_OUT\n",
    "    )\n",
    "    model_in[\"labels\"] = model_out[\"input_ids\"]\n",
    "    return model_in\n",
    "\n",
    "# 4) Appliquer le preprocessing sur chaque split et supprimer les colonnes brutes q_fr/a_fr\n",
    "train_ds = train_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=[input_col, target_col]\n",
    ")\n",
    "val_ds = val_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=[input_col, target_col]\n",
    ")\n",
    "test_ds = test_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=[input_col, target_col]\n",
    ")\n",
    "\n",
    "# 5) Vérification finale\n",
    "print(\"Après map, colonnes :\", train_ds.column_names)\n",
    "print(\"Exemple de clés :\", train_ds[0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Debug (optionnel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels uniques dans le batch : {1, 520, 3082, 188426, 1052, 557, 138801, 577, 3654, 7241, 21070, 9295, 10832, 66142, 1124, 613, 4203, 1648, 1143, 22147, 20104, 12424, 1169, 21151, 3760, 6321, 38583, 77507, 22737, 11477, 1754, 750, 1273, 3840, 7938, 259, 260, 261, 263, 7434, 267, 21259, 8461, 270, 269, 32522, 274, 59154, 277, 283, 16161, 289, 295, 299, 300, 303, 57147, 210238, 331, 335, 340, 82268, 865, 37734, 360, 41325, 3953, 886, 383, 9095, 2952, 391, 47504, 139679, 18338, 429, 430, 1465, 1468, 91587, 26572, 5582, 20954, 475, 110047, 483, 498, 5119}\n",
      "Loss calculée sur ce batch : 33.819705963134766\n"
     ]
    }
   ],
   "source": [
    "# ─── Cellule Debug – Vérification des labels et de la loss sur un batch ───\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Créer un DataLoader minimal avec votre collator\n",
    "dl = DataLoader(train_ds, batch_size=4, collate_fn=collator)\n",
    "\n",
    "# 2. Récupérer le premier batch\n",
    "batch = next(iter(dl))\n",
    "\n",
    "# 3. Afficher quelques labels\n",
    "labels = batch[\"labels\"][0]             # premier exemple\n",
    "unique = set(labels.tolist())\n",
    "print(\"Labels uniques dans le batch :\", unique)\n",
    "\n",
    "# 4. Calculer la loss manuellement\n",
    "batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    loss = model(**batch).loss\n",
    "print(\"Loss calculée sur ce batch :\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version : 4.52.4\n",
      "TrainingArguments vient de : /home/maxime/DataDevIA/chatbotcoach_project/.venv/lib/python3.12/site-packages/transformers/training_args.py\n"
     ]
    }
   ],
   "source": [
    "import transformers, inspect, os, sys\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "print(\"Transformers version :\", transformers.__version__)\n",
    "print(\"TrainingArguments vient de :\", inspect.getfile(TrainingArguments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition des metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cellule 4.5 – Définition de compute_metrics ───\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# On charge la métrique ROUGE (vous pouvez en ajouter d'autres, ex. sacrebleu)\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Prend en entrée un tuple (predictions, labels) où :\n",
    "      - predictions est un np.ndarray de shape (batch_size, max_len)\n",
    "      - labels       est un np.ndarray de shape (batch_size, max_len)\n",
    "    Retourne un dict { 'rougeL': float, ... }\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    # Si votre modèle renvoie un tuple, prenez preds[0]\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    # Décodage en texte\n",
    "    decoded_preds  = tok.batch_decode(preds,  skip_special_tokens=True)\n",
    "    decoded_labels = tok.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE veut des listes de strings\n",
    "    result = rouge.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        rouge_types=[\"rougeL\"]\n",
    "    )\n",
    "    # On prend la fmeasure médiane\n",
    "    rougeL_f = result[\"rougeL\"].mid.fmeasure\n",
    "\n",
    "    # Vous pouvez renvoyer plusieurs métriques si besoin\n",
    "    return {\n",
    "        \"rougeL\": rougeL_f,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "≈ 481 pas par époque\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28339/1814725190.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "# ─── Cellule 5 corrigée – Configuration de l'entraînement ───\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments  # importe la bonne classe\n",
    "\n",
    "# 0) Calcul du nombre de pas par époque\n",
    "steps_per_epoch = len(train_ds) // (2 * 4)\n",
    "print(\"≈\", steps_per_epoch, \"pas par époque\")\n",
    "\n",
    "# 1) Charger & configurer le modèle\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# 2) Collator\n",
    "collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tok,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100\n",
    ")\n",
    "\n",
    "# 3) Arguments d'entraînement (Seq2SeqTrainingArguments gère generate & compute_metrics)\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"mt5_fitness_ckpt\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    num_train_epochs=5,\n",
    "\n",
    "    # évaluation & sauvegarde en nombre de pas\n",
    "    eval_steps=steps_per_epoch,\n",
    "    save_steps=steps_per_epoch,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    logging_steps=50,\n",
    "    report_to=[\"tensorboard\"],\n",
    "\n",
    "    # options de génération pour compute_metrics\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=MAX_OUT,\n",
    "\n",
    "    # pour sauver en safetensors\n",
    "    save_safetensors=True,\n",
    ")\n",
    "\n",
    "# 4) Instanciation du Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tok,                   # nécessaire pour la génération\n",
    "    compute_metrics=compute_metrics, # si vous l'avez défini plus haut\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2410' max='2410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2410/2410 18:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2410, training_loss=0.0, metrics={'train_runtime': 1130.5496, 'train_samples_per_second': 17.049, 'train_steps_per_second': 2.132, 'total_flos': 3821868859392000.0, 'train_loss': 0.0, 'epoch': 5.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cellule 6 – Entraînement\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mt5_fitness_ckpt/tokenizer_config.json',\n",
       " 'mt5_fitness_ckpt/special_tokens_map.json',\n",
       " 'mt5_fitness_ckpt/spiece.model',\n",
       " 'mt5_fitness_ckpt/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# après trainer.train()\n",
    "trainer.save_model(\"mt5_fitness_ckpt\")  # ceci enregistre les weights dans mt5_fitness_ckpt\n",
    "tok.save_pretrained(\"mt5_fitness_ckpt\") # ceci enregistre le tokenizer (fichiers .model, config…)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chargement du modele\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 512)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "import torch\n",
    "\n",
    "checkpoint_dir = \"mt5_fitness_ckpt\"\n",
    "\n",
    "# 2.1 Charger le tokenizer qui est maintenant dans mt5_fitness_ckpt\n",
    "tok = MT5Tokenizer.from_pretrained(checkpoint_dir)\n",
    "\n",
    "# 2.2 Charger le modèle fine-tuné\n",
    "model = MT5ForConditionalGeneration.from_pretrained(checkpoint_dir)\n",
    "\n",
    "# 2.3 Mettre sur GPU si dispo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> question: Comment améliorer mon endurance pour la course à pied ?\n",
      "→ <extra_id_0>.\n",
      "\n",
      "> question: Quel est le meilleur programme d'entraînement pour perdre du poids ?\n",
      "→ <extra_id_0>.\n",
      "\n",
      "> question: Quels étirements faire après une séance de squat ?\n",
      "→ <extra_id_0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ─── Cellule 7 – Inference rapide ───\n",
    "from transformers import Text2TextGenerationPipeline\n",
    "\n",
    "# 1) Créer un pipeline de génération\n",
    "pipe = Text2TextGenerationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "# 2) Quelques questions d’exemple\n",
    "questions = [\n",
    "    \"question: Comment améliorer mon endurance pour la course à pied ?\",\n",
    "    \"question: Quel est le meilleur programme d'entraînement pour perdre du poids ?\",\n",
    "    \"question: Quels étirements faire après une séance de squat ?\",\n",
    "]\n",
    "\n",
    "# 3) Générer les réponses\n",
    "for q in questions:\n",
    "    out = pipe(q, max_length=128, num_beams=4, early_stopping=True)\n",
    "    print(f\"> {q}\\n→ {out[0]['generated_text']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
