# api/fitness_service.py - Version corrigÃ©e pour SafeTensors

import os
import logging
import torch
import numpy as np
from datetime import datetime
from typing import List, Dict, Optional, Any
from pathlib import Path

# Imports IA
from transformers import AutoModelForCausalLM, AutoTokenizer
try:
    from sentence_transformers import SentenceTransformer
    import faiss
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False

logger = logging.getLogger(__name__)

class FitnessCoachService:
    """Service principal avec votre modÃ¨le DistilGPT-2 fine-tunÃ©"""
    
    def __init__(self, model_path: str = "./models/coach-sportif-french"):
        self.model_path = Path(model_path)
        self.device = self._get_device()
        
        # Ã‰tat
        self.model_loaded = False
        self.rag_enabled = False
        self.initialization_time = None
        self.initialization_error = None
        
        # Composants
        self.tokenizer = None
        self.model = None
        self.embedding_model = None
        self.faiss_index = None
        self.exercise_database = []
        
        # Statistiques
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'fallback_requests': 0,
            'average_response_time': 0.0,
            'last_request_time': None
        }
        
        # Configuration gÃ©nÃ©ration
        self.generation_config = {
            'max_new_tokens': 150,
            'temperature': 0.7,
            'do_sample': True,
            'top_p': 0.9,
            'top_k': 50,
            'repetition_penalty': 1.1,
            'no_repeat_ngram_size': 3
        }
        
        # Initialiser
        self._load_exercise_database()
        self._initialize_service()
    
    def _get_device(self):
        """DÃ©termine le device optimal"""
        if torch.cuda.is_available():
            device = torch.device("cuda")
            logger.info(f"ðŸš€ GPU dÃ©tectÃ©: {torch.cuda.get_device_name()}")
        else:
            device = torch.device("cpu")
            logger.info("ðŸ’» Utilisation CPU")
        return device
    
    def _initialize_service(self):
        """Initialise le service complet avec gestion d'erreurs amÃ©liorÃ©e"""
        start_time = datetime.now()
        
        try:
            logger.info("ðŸ‹ï¸ Initialisation Coach Fitness...")
            logger.info(f"ðŸ“ Chemin modÃ¨le: {self.model_path.absolute()}")
            
            # VÃ©rifier existence du modÃ¨le
            if not self.model_path.exists():
                error_msg = f"Dossier modÃ¨le non trouvÃ©: {self.model_path.absolute()}"
                logger.error(f"âŒ {error_msg}")
                self.initialization_error = error_msg
                self._suggest_model_fix()
                return
            
            # VÃ©rifier fichiers requis avec support SafeTensors
            required_files = ["config.json"]
            model_files = ["pytorch_model.bin", "model.safetensors"]
            
            missing_base = []
            for file in required_files:
                if not (self.model_path / file).exists():
                    missing_base.append(file)
            
            # VÃ©rifier au moins un fichier de modÃ¨le
            model_file_found = None
            for model_file in model_files:
                if (self.model_path / model_file).exists():
                    model_file_found = model_file
                    break
            
            if missing_base:
                error_msg = f"Fichiers de base manquants dans {self.model_path}: {missing_base}"
                logger.error(f"âŒ {error_msg}")
                self.initialization_error = error_msg
                return
            
            if not model_file_found:
                error_msg = f"Aucun fichier de modÃ¨le trouvÃ© dans {self.model_path}"
                logger.error(f"âŒ {error_msg}")
                self.initialization_error = error_msg
                return
            
            logger.info(f"âœ… Fichiers modÃ¨le dÃ©tectÃ©s: {model_file_found}")
            
            # 1. Charger DistilGPT-2
            logger.info("ðŸ¤– Chargement du modÃ¨le DistilGPT-2...")
            self._load_model()
            
            # 2. Charger RAG (optionnel)
            if RAG_AVAILABLE:
                logger.info("ðŸ“Š Chargement du systÃ¨me RAG...")
                self._load_rag()
            else:
                logger.warning("âš ï¸ RAG non disponible (dÃ©pendances manquantes)")
            
            self.model_loaded = True
            self.initialization_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"âœ… Service initialisÃ© avec succÃ¨s en {self.initialization_time:.2f}s")
            logger.info(f"ðŸ“± Device: {self.device}")
            logger.info(f"ðŸ¤– ModÃ¨le: DistilGPT-2 fine-tunÃ©")
            logger.info(f"ðŸ“Š RAG: {'ActivÃ©' if self.rag_enabled else 'DÃ©sactivÃ©'}")
            
        except Exception as e:
            error_msg = f"Erreur lors de l'initialisation: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            self.initialization_error = error_msg
            self.model_loaded = False
            self._suggest_model_fix()
    
    def _suggest_model_fix(self):
        """Suggestions pour corriger les problÃ¨mes de modÃ¨le"""
        logger.info("\nðŸ”§ SUGGESTIONS DE CORRECTION:")
        logger.info("1. VÃ©rifier le chemin du modÃ¨le:")
        logger.info(f"   ls -la {self.model_path}")
        logger.info("2. Diagnostic complet:")
        logger.info("   python diagnostic_model_fixed.py")
        logger.info("3. Installer accelerate si nÃ©cessaire:")
        logger.info("   pip install accelerate")
    
    def _load_model(self):
        """Charge votre modÃ¨le DistilGPT-2 fine-tunÃ© avec support SafeTensors"""
        try:
            logger.info(f"ðŸ“š Chargement tokenizer depuis: {self.model_path}")
            
            # Tokenizer avec gestion d'erreurs
            self.tokenizer = AutoTokenizer.from_pretrained(str(self.model_path))
            
            # Configurer pad token si nÃ©cessaire
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
                logger.info("ðŸ”§ Pad token configurÃ©")
            
            # Mettre Ã  jour config gÃ©nÃ©ration
            self.generation_config['pad_token_id'] = self.tokenizer.pad_token_id
            self.generation_config['eos_token_id'] = self.tokenizer.eos_token_id
            
            logger.info(f"âœ… Tokenizer chargÃ©. Vocabulaire: {len(self.tokenizer.vocab)}")
            
            # DÃ©tection du format de modÃ¨le
            if (self.model_path / "model.safetensors").exists():
                logger.info("ðŸ”’ Format SafeTensors dÃ©tectÃ©")
            elif (self.model_path / "pytorch_model.bin").exists():
                logger.info("âš¡ Format PyTorch dÃ©tectÃ©")
            
            # ModÃ¨le avec options adaptÃ©es (SANS low_cpu_mem_usage pour Ã©viter accelerate)
            logger.info(f"âš¡ Chargement modÃ¨le sur {self.device}...")
            self.model = AutoModelForCausalLM.from_pretrained(
                str(self.model_path),
                torch_dtype=torch.float16 if self.device.type == "cuda" else torch.float32,
                # Retirer low_cpu_mem_usage pour Ã©viter accelerate
            )
            self.model.to(self.device)
            self.model.eval()
            
            logger.info("âœ… ModÃ¨le DistilGPT-2 chargÃ© avec succÃ¨s")
            
        except Exception as e:
            logger.error(f"âŒ Erreur chargement modÃ¨le: {e}")
            raise
    
    def _load_rag(self):
        """Charge le systÃ¨me RAG (optionnel)"""
        try:
            logger.info("ðŸ“Š Chargement RAG...")
            
            # ModÃ¨le embeddings
            self.embedding_model = SentenceTransformer(
                "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
            
            # Construire index FAISS
            self._build_faiss_index()
            
            self.rag_enabled = True
            logger.info("âœ… RAG activÃ©")
            
        except Exception as e:
            logger.error(f"âš ï¸ RAG non disponible: {e}")
            self.rag_enabled = False
    
    def _load_exercise_database(self):
        """Base d'exercices pour RAG"""
        self.exercise_database = [
            {
                "id": 1,
                "title": "Pompes classiques",
                "content": "Exercice fondamental pour pectoraux, triceps et deltoÃ¯des. Position planche, mains largeur d'Ã©paules, descendre contrÃ´lÃ©e jusqu'Ã  frÃ´ler le sol. 3 sÃ©ries de 8-12 rÃ©pÃ©titions pour dÃ©butants.",
                "muscle_groups": ["pectoraux", "triceps", "deltoÃ¯des"],
                "difficulty": "dÃ©butant",
                "equipment": "aucun"
            },
            {
                "id": 2,
                "title": "Squats parfaits",
                "content": "Mouvement roi pour quadriceps et fessiers. Pieds largeur d'Ã©paules, descendre comme pour s'asseoir, garder dos droit. 3 sÃ©ries de 12-20 rÃ©pÃ©titions.",
                "muscle_groups": ["quadriceps", "fessiers", "mollets"],
                "difficulty": "dÃ©butant",
                "equipment": "aucun"
            },
            {
                "id": 3,
                "title": "Planche abdominale",
                "content": "Gainage statique pour core et stabilitÃ©. Position sur avant-bras, corps alignÃ©, contracter abdos et fessiers. Tenir 30 secondes Ã  2 minutes.",
                "muscle_groups": ["abdominaux", "core", "Ã©paules"],
                "difficulty": "dÃ©butant",
                "equipment": "aucun"
            },
            {
                "id": 4,
                "title": "Nutrition sportive",
                "content": "Hydratation 2-3L/jour, protÃ©ines 20-25g post-effort dans les 30min. PrivilÃ©gier sources complÃ¨tes: Å“ufs, poisson, viande maigre.",
                "category": "nutrition",
                "importance": "haute"
            },
            {
                "id": 5,
                "title": "RÃ©cupÃ©ration optimale",
                "content": "Sommeil 7-9h/nuit prioritÃ© absolue. Ã‰tirements post-effort 30s par muscle. Repos actif entre sÃ©ances intenses.",
                "category": "rÃ©cupÃ©ration",
                "importance": "critique"
            }
        ]
    
    def _build_faiss_index(self):
        """Construit index FAISS pour recherche sÃ©mantique"""
        if not self.embedding_model:
            return
        
        try:
            # CrÃ©er embeddings
            texts = [f"{item['title']} {item['content']}" for item in self.exercise_database]
            embeddings = self.embedding_model.encode(texts, show_progress_bar=False)
            
            # Index FAISS
            dimension = embeddings.shape[1]
            self.faiss_index = faiss.IndexFlatIP(dimension)
            
            # Normaliser et ajouter
            faiss.normalize_L2(embeddings)
            self.faiss_index.add(embeddings.astype('float32'))
            
            logger.info(f"âœ… Index FAISS: {self.faiss_index.ntotal} documents")
            
        except Exception as e:
            logger.error(f"âŒ Erreur FAISS: {e}")
            self.faiss_index = None
    
    def search_relevant_context(self, query: str, top_k: int = 3) -> List[Dict]:
        """Recherche contexte via RAG"""
        if not self.rag_enabled or not self.faiss_index:
            return self.exercise_database[:top_k]
        
        try:
            # Encoder query
            query_embedding = self.embedding_model.encode([query], show_progress_bar=False)
            faiss.normalize_L2(query_embedding)
            
            # Rechercher
            scores, indices = self.faiss_index.search(
                query_embedding.astype('float32'), 
                min(top_k, len(self.exercise_database))
            )
            
            # Retourner documents
            relevant_docs = []
            for i, idx in enumerate(indices[0]):
                if idx >= 0 and idx < len(self.exercise_database):
                    doc = self.exercise_database[idx].copy()
                    doc['relevance_score'] = float(scores[0][i])
                    relevant_docs.append(doc)
            
            return [doc for doc in relevant_docs if doc['relevance_score'] > 0.2]
            
        except Exception as e:
            logger.error(f"âŒ Erreur recherche: {e}")
            return self.exercise_database[:top_k]
    
    def _create_prompt(self, question: str, context_docs: List[Dict]) -> str:
        """CrÃ©e prompt optimisÃ© pour votre modÃ¨le fine-tunÃ©"""
        # Contexte RAG
        context_text = ""
        if context_docs:
            context_parts = []
            for doc in context_docs[:2]:
                context_parts.append(f"- {doc['title']}: {doc['content'][:150]}...")
            context_text = "\n".join(context_parts)
        
        # Format optimisÃ© pour votre modÃ¨le
        prompt = f"""[COACH] En tant que coach sportif franÃ§ais certifiÃ©, voici les informations pertinentes :

{context_text}

Question: {question}

RÃ©ponse: """
        
        return prompt
    
    def _post_process_response(self, response: str) -> str:
        """Post-traitement franÃ§ais"""
        if not response:
            return "DÃ©solÃ©, je n'ai pas pu gÃ©nÃ©rer une rÃ©ponse appropriÃ©e."
        
        # Nettoyer
        cleaned = response.strip()
        
        # Supprimer artefacts prompt
        for artifact in ["[COACH]", "Question:", "RÃ©ponse:"]:
            if artifact in cleaned:
                cleaned = cleaned.split(artifact)[-1].strip()
        
        # Nettoyer caractÃ¨res
        cleaned = cleaned.replace("\\n", " ").replace("  ", " ")
        
        # Limiter longueur
        if len(cleaned) > 400:
            sentences = cleaned.split('.')
            cleaned = '. '.join(sentences[:3])
            if not cleaned.endswith('.'):
                cleaned += '.'
        
        # Assurer fin propre
        if not cleaned.endswith(('.', '!', '?')):
            cleaned += '.'
        
        return cleaned
    
    def generate_advice(self, question: str, user_profile: Optional[Dict] = None) -> Dict[str, Any]:
        """GÃ©nÃ¨re conseil avec votre modÃ¨le DistilGPT-2"""
        start_time = datetime.now()
        self.stats['total_requests'] += 1
        
        try:
            # 1. Recherche contexte RAG
            relevant_docs = self.search_relevant_context(question, top_k=3)
            
            # 2. VÃ©rifier modÃ¨le
            if not self.model_loaded:
                return self._fallback_response(question, relevant_docs)
            
            # 3. CrÃ©er prompt
            prompt = self._create_prompt(question, relevant_docs)
            
            # 4. Tokeniser avec attention_mask
            inputs = self.tokenizer.encode(
                prompt, 
                return_tensors='pt', 
                truncation=True, 
                max_length=512
            ).to(self.device)
            
            # CrÃ©er attention_mask pour Ã©viter le warning
            attention_mask = torch.ones_like(inputs)
            
            # 5. GÃ©nÃ©rer avec votre modÃ¨le DistilGPT-2
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    attention_mask=attention_mask,  # Ajouter attention_mask
                    max_length=inputs.shape[1] + self.generation_config['max_new_tokens'],
                    temperature=self.generation_config['temperature'],
                    do_sample=self.generation_config['do_sample'],
                    top_p=self.generation_config['top_p'],
                    top_k=self.generation_config['top_k'],
                    repetition_penalty=self.generation_config['repetition_penalty'],
                    no_repeat_ngram_size=self.generation_config['no_repeat_ngram_size'],
                    pad_token_id=self.generation_config['pad_token_id'],
                    eos_token_id=self.generation_config['eos_token_id']
                )
            
            # 6. DÃ©coder et post-traiter
            raw_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            generated_text = raw_response[len(prompt):].strip()
            final_response = self._post_process_response(generated_text)
            
            # 7. Statistiques
            response_time = (datetime.now() - start_time).total_seconds()
            self.stats['successful_requests'] += 1
            self.stats['last_request_time'] = datetime.now()
            
            # Moyenne mobile
            self.stats['average_response_time'] = (
                (self.stats['average_response_time'] * (self.stats['successful_requests'] - 1) + response_time) 
                / self.stats['successful_requests']
            )
            
            return {
                'response': final_response,
                'sources': [doc.get('title', 'Document') for doc in relevant_docs],
                'context_used': len(relevant_docs) > 0,
                'model_used': 'distilgpt2_finetuned',
                'response_time': response_time,
                'confidence': 'high' if len(relevant_docs) > 0 else 'medium',
                'rag_enabled': self.rag_enabled
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration: {e}")
            self.stats['fallback_requests'] += 1
            return self._fallback_response(question, relevant_docs if 'relevant_docs' in locals() else [])
    
    def _fallback_response(self, question: str, relevant_docs: List[Dict]) -> Dict[str, Any]:
        """RÃ©ponse de fallback"""
        # RÃ©ponses basÃ©es sur mots-clÃ©s
        fallback_map = {
            'pompes': "ðŸ‹ï¸ **Pompes parfaites** : Position planche, mains largeur d'Ã©paules, corps alignÃ©. Descendre contrÃ´lÃ©e jusqu'Ã  frÃ´ler le sol, remonter en poussant. 3 sÃ©ries de 8-12 rÃ©pÃ©titions pour dÃ©buter. Focus sur la technique avant la quantitÃ© !",
            'squat': "ðŸ‹ï¸ **Squats efficaces** : Pieds largeur d'Ã©paules, descendre comme pour s'asseoir, genoux alignÃ©s avec pieds. 3 sÃ©ries de 12-20 rÃ©pÃ©titions. Excellent pour quadriceps et fessiers !",
            'cardio': "â¤ï¸ **Cardio dÃ©butant** : Marche rapide 30-45min, 3-4x/semaine. Progression graduelle vers alternance marche/course. L'important c'est la rÃ©gularitÃ© !",
            'nutrition': "ðŸ¥— **Nutrition sportive** : Hydratation 2-3L/jour, protÃ©ines 20-25g post-effort, alimentation Ã©quilibrÃ©e. Les bases font la diffÃ©rence !",
            'rÃ©cupÃ©ration': "ðŸ˜´ **RÃ©cupÃ©ration optimale** : Sommeil 7-9h/nuit, Ã©tirements post-effort, repos actif. La rÃ©cupÃ©ration fait partie de l'entraÃ®nement !"
        }
        
        # Chercher rÃ©ponse appropriÃ©e
        question_lower = question.lower()
        response_text = None
        
        for keyword, response in fallback_map.items():
            if keyword in question_lower:
                response_text = response
                break
        
        # Utiliser contexte RAG si disponible
        if not response_text and relevant_docs:
            best_doc = relevant_docs[0]
            response_text = f"**{best_doc['title']}** : {best_doc['content'][:200]}... ðŸ’ª"
        
        # RÃ©ponse gÃ©nÃ©rale
        if not response_text:
            response_text = "ðŸ‹ï¸ **Conseils fitness gÃ©nÃ©raux** : Commencez par Ã©chauffement 5-10min, exercices au poids du corps (pompes, squats, planche), 3 sÃ©ries selon votre niveau, rÃ©cupÃ©ration avec Ã©tirements. Progression graduelle et Ã©coute du corps essentielles ! ðŸ’ª"
        
        return {
            'response': response_text,
            'sources': [doc.get('title', 'Document') for doc in relevant_docs] if relevant_docs else ['Conseils de base'],
            'context_used': len(relevant_docs) > 0,
            'model_used': 'fallback_rag',
            'response_time': 0.1,
            'confidence': 'medium',
            'rag_enabled': self.rag_enabled
        }
    
    def get_exercise_recommendations(self, muscle_groups=None, difficulty=None, equipment=None):
        """Recommandations d'exercices"""
        filtered = []
        for exercise in self.exercise_database:
            if muscle_groups and 'muscle_groups' in exercise:
                if not any(muscle in exercise['muscle_groups'] for muscle in muscle_groups):
                    continue
            if difficulty and exercise.get('difficulty') != difficulty:
                continue
            if equipment and exercise.get('equipment') != equipment:
                continue
            filtered.append(exercise)
        return filtered
    
    def get_service_stats(self) -> Dict[str, Any]:
        """Statistiques du service"""
        return {
            'status': 'healthy' if self.model_loaded else 'degraded',
            'model_loaded': self.model_loaded,
            'rag_enabled': self.rag_enabled,
            'device': str(self.device),
            'initialization_time': self.initialization_time,
            'initialization_error': self.initialization_error,
            'stats': self.stats.copy(),
            'exercise_database_size': len(self.exercise_database),
            'timestamp': datetime.now().isoformat()
        }

# Instance globale
_fitness_service = None

def get_fitness_service(model_path: str = "./models/coach-sportif-french"):
    """Singleton du service"""
    global _fitness_service
    
    if _fitness_service is None:
        logger.info("ðŸš€ Initialisation service fitness...")
        _fitness_service = FitnessCoachService(model_path)
    
    return _fitness_service